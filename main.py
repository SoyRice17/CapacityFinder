#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from gui import MainWindow
import sys
import os
import re
import json
import logging
from datetime import datetime
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from PyQt5.QtWidgets import QApplication

# ë¡œê·¸ ì„¤ì • í•¨ìˆ˜
def setup_logging():
    """ë¡œê·¸ ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ë¡œê·¸ íŒŒì¼ëª… (ë‚ ì§œ í¬í•¨)
    log_filename = os.path.join(log_dir, f"capacity_finder_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ë¡œê·¸ í¬ë§· ì„¤ì • (íŒŒì¼ëª…, í•¨ìˆ˜ëª…, ë¼ì¸ ë²ˆí˜¸ í¬í•¨)
    log_format = "%(asctime)s - %(levelname)s - [%(filename)s:%(funcName)s:%(lineno)d] - %(message)s"
    
    # ë¡œê·¸ ì„¤ì • - ëª¨ë“  ë ˆë²¨ ì¶œë ¥ (DEBUG í¬í•¨)
    logging.basicConfig(
        level=logging.DEBUG,
        format=log_format,
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),  # íŒŒì¼ ì¶œë ¥
            logging.StreamHandler()  # ì½˜ì†” ì¶œë ¥
        ]
    )
    
    # ë¡œê±° ë°˜í™˜
    return logging.getLogger(__name__)

# ë¡œê·¸ ì„¤ì • ì´ˆê¸°í™”
logger = setup_logging()

# ë‹¤ë¥¸ íŒŒì¼ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¡œê·¸ ì„¤ì • í•¨ìˆ˜ ì œê³µ
def get_logger(module_name):
    """ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ë¡œê±°ë¥¼ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©"""
    return logging.getLogger(module_name)

class IntelligentCurationSystem:
    """ì§€ëŠ¥í˜• íë ˆì´ì…˜ ì‹œìŠ¤í…œ - ë ˆì´íŒ… ë°ì´í„°ì™€ íŒŒì¼ ì ìˆ˜ë¥¼ ê²°í•©í•œ íŒë‹¨ ì‹œìŠ¤í…œ"""
    
    def __init__(self, ratings_file="user_ratings.json"):
        self.ratings_file = ratings_file
        self.ratings_data = self.load_ratings()
        self.keyword_weights = self.load_keyword_weights()
        logger.info("ğŸ§  ì§€ëŠ¥í˜• íë ˆì´ì…˜ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ (ë‹¤ì–‘ì„± ìœ ì§€ ì ìˆ˜ ì‹œìŠ¤í…œ ì ìš©)")
    
    def load_ratings(self):
        """ë ˆì´íŒ… ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.ratings_file):
                with open(self.ratings_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    return data.get('ratings', {})
            return {}
        except Exception as e:
            logger.error(f"ë ˆì´íŒ… ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {}
    
    def load_keyword_weights(self):
        """í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ì—ì„œ ë¡œë“œí•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©"""
        try:
            # ì €ì¥ëœ í‚¤ì›Œë“œ íŒŒì¼ í™•ì¸
            if os.path.exists('keyword_weights.json'):
                with open('keyword_weights.json', 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    keywords = data.get('keywords', {})
                    if keywords:
                        logger.info(f"í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ íŒŒì¼ ë¡œë“œ: {len(keywords)}ê°œ í‚¤ì›Œë“œ")
                        return keywords
        except Exception as e:
            logger.error(f"í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì˜¤ë¥˜: {e}")
        
        # ê¸°ë³¸ê°’ ì‚¬ìš©
        logger.info("ê¸°ë³¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‚¬ìš©")
        return self.get_default_keyword_weights()
    
    def get_default_keyword_weights(self):
        """ê¸°ë³¸ í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì‹œìŠ¤í…œ êµ¬ì¶• - ë‹¤ì–‘ì„± ìœ ì§€ ë²„ì „"""
        return {
            # ê¸ì •ì  í‚¤ì›Œë“œ (ìœ ì§€ ì„ í˜¸) - ì ë‹¹í•œ ë²”ìœ„ë¡œ ì¡°ì •
            'ã……ã…Œã…Š': 0.8,         # 1.2 â†’ 0.8
            'ã…†ã……ã…Œã…Š': 0.9,        # 1.5 â†’ 0.9
            'ã…ˆã……ã…Œã…Š': 0.7,        # 1.0 â†’ 0.7
            'ã…ã……ã…Œã…Š': 0.6,        # 0.8 â†’ 0.6
            'GOAT': 0.9,          # 1.5 â†’ 0.9
            'ì‹ ': 0.8,            # 1.3 â†’ 0.8
            'ê·€ì—¬ì›€': 0.6,         # 1.0 â†’ 0.6
            'ì˜¬ë…¸': 0.5,          # 0.9 â†’ 0.5
            'ììœ„': 0.4,          # 0.7 â†’ 0.4
            
            # ë¶€ì •ì  í‚¤ì›Œë“œ (ì‚­ì œ ì„ í˜¸) - ì ë‹¹í•œ ë²”ìœ„ë¡œ ì¡°ì •
            'ê°€ì§€ì¹˜ê¸°í•„ìš”': -0.8,    # -1.5 â†’ -0.8
            'ë…¹í™”ì¤‘ì§€': -0.6,       # -1.0 â†’ -0.6
            'ë…¹í™”ì¤‘ë‹¨': -0.6,       # -1.0 â†’ -0.6
            'ì¶”ì ì¤‘ì§€': -0.7,       # -1.2 â†’ -0.7
            'í˜„ì¬': -0.4,          # -0.6 â†’ -0.4
            'ì• ë§¤í•¨': -0.5,         # -0.8 â†’ -0.5
            'ê³„ë¥µ': -0.7,          # -1.3 â†’ -0.7
            'ì •ìœ¼ë¡œë³´ëŠ”ëŠë‚Œ': -0.6,   # -1.0 â†’ -0.6
            'ã…ã…Œã…Š': -0.3,         # -0.5 â†’ -0.3
            
            # ì¤‘ë¦½ í‚¤ì›Œë“œ (ë‹¤ì–‘ì„± í™•ëŒ€)
            'ì–¼êµ´': 0.1,
            'ìœ¡ë•': 0.2,
            'ì½”ìŠ¤': 0.1,
            '2ì¸': 0.1,
            '3ì¸': 0.1,
            'ì„¹ì‹œ': 0.3,
            'ì˜ˆì¨': 0.2,
            'ëª¸ë§¤': 0.2,
            'ìƒëƒ¥': 0.3,
            'ì¸¤ë°ë ˆ': 0.2,
        }
    
    def calculate_rating_score(self, username):
        """ì‚¬ìš©ì ë ˆì´íŒ… ê¸°ë°˜ ì ìˆ˜ ê³„ì‚° (0.0 ~ 1.0) - ë‹¤ì–‘ì„± ìœ ì§€ ì‹œìŠ¤í…œ"""
        if username not in self.ratings_data:
            return 0.4  # ë¯¸í‰ê°€ ì‚¬ìš©ì ê¸°ë³¸ ì ìˆ˜ (0.2 â†’ 0.4ë¡œ ìƒí–¥)
        
        rating_info = self.ratings_data[username]
        base_rating = rating_info.get('rating', 0) / 5.0  # 0.0 ~ 1.0 ì •ê·œí™”
        comment = rating_info.get('comment', '').lower()
        
        # í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì ìš© (ë²”ìœ„ ì¡°ì •)
        keyword_bonus = 0.0
        for keyword, weight in self.keyword_weights.items():
            if keyword in comment:
                keyword_bonus += weight
        
        # í‚¤ì›Œë“œ ë³´ë„ˆìŠ¤ ì œí•œ ì¡°ì • (-0.7 ~ +0.7)
        keyword_bonus = max(-0.7, min(0.7, keyword_bonus))
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
        raw_score = base_rating + keyword_bonus
        raw_score = max(0.0, min(1.0, raw_score))
        
        # ë‹¤ì–‘ì„± ë³´ì • ì ìš© (ë¶€ë“œëŸ¬ìš´ ê³¡ì„ )
        final_score = self._apply_diversity_adjustment(raw_score)
        
        return final_score
    
    def calculate_composite_score(self, username, file_info, user_files):
        """ë³µí•© ì ìˆ˜ ê³„ì‚°: íŒŒì¼ ì ìˆ˜ + ë ˆì´íŒ… ì ìˆ˜"""
        # ê¸°ë³¸ íŒŒì¼ ì ìˆ˜ (0.0 ~ 1.0)
        file_score = self.calculate_file_score_basic(file_info, user_files)
        
        # ë ˆì´íŒ… ì ìˆ˜ (0.0 ~ 1.0)
        rating_score = self.calculate_rating_score(username)
        
        # ê°€ì¤‘ ê²°í•© (íŒŒì¼ ì ìˆ˜ 60%, ë ˆì´íŒ… ì ìˆ˜ 40%)
        composite_score = (file_score * 0.6) + (rating_score * 0.4)
        
        return {
            'composite_score': composite_score,
            'file_score': file_score,
            'rating_score': rating_score,
            'username': username
        }
    
    def calculate_file_score_basic(self, file_info, user_files):
        """ê¸°ë³¸ íŒŒì¼ ì ìˆ˜ ê³„ì‚° (ë‹¤ì–‘ì„± ìœ ì§€ ì‹œìŠ¤í…œ)"""
        file_name = file_info['name']
        file_size = file_info['size']
        
        size_score = 0.0
        rarity_score = 0.0
        date_score = 0.0
        
        try:
            # íŒŒì¼ í¬ê¸° ì ìˆ˜ (ì ë‹¹í•œ ê³¡ì„ )
            all_sizes = [f['size'] for f in user_files]
            if all_sizes:
                max_size = max(all_sizes)
                min_size = min(all_sizes)
                if max_size > min_size:
                    normalized_score = (file_size - min_size) / (max_size - min_size)
                    # 1.5ì œê³±ìœ¼ë¡œ ì ë‹¹í•œ ê³¡ì„  ìœ ì§€
                    size_score = normalized_score ** 1.5  # ë„ˆë¬´ ê·¹ë‹¨ì ì´ì§€ ì•Šê²Œ
                else:
                    size_score = 0.6  # í¬ê¸° ì°¨ì´ ì—†ìœ¼ë©´ ì¤‘ìƒ ì ìˆ˜
            
            # í¬ê·€ì„± ì ìˆ˜ (ê¸°ë³¸ê°’ ìƒí–¥)
            rarity_score = 0.5  # ê¸°ë³¸ê°’ (0.3 â†’ 0.5ë¡œ ìƒí–¥)
            
            # ë‚ ì§œ ì ìˆ˜ (ê¸°ë³¸ê°’ ìƒí–¥)
            date_score = 0.4  # ê¸°ë³¸ê°’ (0.2 â†’ 0.4ë¡œ ìƒí–¥)
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return 0.3  # ì˜¤ë¥˜ ì‹œ ê¸°ë³¸ê°’ì„ ì ë‹¹í•˜ê²Œ (0.1 â†’ 0.3)
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        raw_score = (size_score * 0.6 + rarity_score * 0.25 + date_score * 0.15)
        
        # ë‹¤ì–‘ì„± ë³´ì • ì ìš©
        final_score = self._apply_diversity_adjustment(raw_score)
        
        return final_score
    
    def _apply_diversity_adjustment(self, score):
        """ë‹¤ì–‘ì„± ìœ ì§€ ë³´ì • í•¨ìˆ˜ - ë¶€ë“œëŸ¬ìš´ ê³¡ì„ ìœ¼ë¡œ 0.01~0.99 ë²”ìœ„ì—ì„œ ê³ ë¥´ê²Œ ë¶„í¬"""
        import math
        
        # ì‹œê·¸ëª¨ì´ë“œ ê³¡ì„  ì ìš©ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ë¶„í¬ ìƒì„±
        # ì…ë ¥ ë²”ìœ„ [0,1]ì„ [-6,6] ë²”ìœ„ë¡œ ë³€í™˜
        x = (score - 0.5) * 12  # -6 ~ +6 ë²”ìœ„
        
        # ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜: 1 / (1 + e^(-x))
        sigmoid = 1.0 / (1.0 + math.exp(-x))
        
        # 0.01 ~ 0.99 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§
        adjusted = 0.01 + (sigmoid * 0.98)
        
        # ì¶”ê°€ ë¯¸ì„¸ ì¡°ì •: ì¤‘ê°„ê°’ ì£¼ë³€ì—ì„œ ë” ë„“ì€ ë¶„í¬
        if 0.3 <= score <= 0.7:
            # ì¤‘ê°„ ì˜ì—­ì—ì„œ ì•½ê°„ì˜ ëœë¤ì„± ì¶”ê°€ (íŒŒì¼ëª… í•´ì‹œ ê¸°ë°˜)
            hash_factor = (hash(str(score)) % 100) / 1000.0  # -0.05 ~ +0.05
            adjusted += hash_factor - 0.05
        
        return max(0.01, min(0.99, adjusted))
    
    def get_deletion_priority_list(self, capacity_finder):
        """ì‚­ì œ ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        priority_list = []
        
        for username, user_data in capacity_finder.dic_files.items():
            files_with_scores = []
            
            for file_info in user_data['files']:
                score_data = self.calculate_composite_score(username, file_info, user_data['files'])
                files_with_scores.append({
                    'name': file_info['name'],
                    'size': file_info['size'],
                    'composite_score': score_data['composite_score'],
                    'file_score': score_data['file_score'],
                    'rating_score': score_data['rating_score'],
                    'username': username
                })
            
            # ì ìˆ˜ ë‚®ì€ ìˆœ ì •ë ¬ (ì‚­ì œ ìš°ì„ ìˆœìœ„)
            files_with_scores.sort(key=lambda x: x['composite_score'])
            
            priority_list.extend(files_with_scores)
        
        return priority_list
    
    def get_auto_deletion_suggestions(self, capacity_finder, target_savings_gb=10):
        """ìë™ ì‚­ì œ ì¶”ì²œ (ëª©í‘œ ì ˆì•½ ìš©ëŸ‰ ê¸°ì¤€) - ë‹¤ì–‘ì„± ìœ ì§€ ê¸°ì¤€"""
        priority_list = self.get_deletion_priority_list(capacity_finder)
        target_savings_mb = target_savings_gb * 1024
        
        suggestions = []
        current_savings = 0
        
        for file_data in priority_list:
            if current_savings >= target_savings_mb:
                break
            
            # ì‚­ì œ ê¸°ì¤€: ë³µí•© ì ìˆ˜ 0.25 ì´í•˜ (ì ë‹¹í•œ ê¸°ì¤€)
            if file_data['composite_score'] <= 0.25:
                suggestions.append(file_data)
                current_savings += file_data['size']
        
        return {
            'suggested_files': suggestions,
            'total_savings_gb': current_savings / 1024,
            'files_count': len(suggestions),
            'criteria': 'composite_score <= 0.25'
        }
    
    def get_user_cleanup_analysis(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ì •ë¦¬ ë¶„ì„"""
        if username not in self.ratings_data:
            return None
        
        rating_info = self.ratings_data[username]
        rating = rating_info.get('rating', 0)
        comment = rating_info.get('comment', '')
        
        # ì •ë¦¬ ì „ëµ ê²°ì •
        if rating <= 2:
            strategy = "ëŒ€ë¶€ë¶„ ì‚­ì œ ê¶Œì¥"
            keep_ratio = 0.1  # 10%ë§Œ ìœ ì§€
        elif rating == 3:
            strategy = "ì„ ë³„ì  ì‚­ì œ"
            keep_ratio = 0.3  # 30% ìœ ì§€
        elif rating >= 4:
            strategy = "ë³´ì¡´ ìš°ì„ "
            keep_ratio = 0.7  # 70% ìœ ì§€
        else:
            strategy = "ê¸°ë³¸ ì •ë¦¬"
            keep_ratio = 0.5  # 50% ìœ ì§€
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¡°ì •
        if 'ê°€ì§€ì¹˜ê¸°í•„ìš”' in comment:
            keep_ratio *= 0.5  # ë” ë§ì´ ì‚­ì œ
        elif 'ë…¹í™”ì¤‘ì§€' in comment:
            keep_ratio *= 0.3  # ëŒ€ë¶€ë¶„ ì‚­ì œ
        elif 'ã……ã…Œã…Š' in comment or 'GOAT' in comment:
            keep_ratio = min(keep_ratio * 1.5, 0.9)  # ë” ë§ì´ ë³´ì¡´
        
        return {
            'username': username,
            'rating': rating,
            'strategy': strategy,
            'keep_ratio': keep_ratio,
            'comment': comment
        }

class SiteType(Enum):
    """ì§€ì›í•˜ëŠ” ì„±ì¸ í”Œë«í¼ ëª©ë¡"""
    CHATURBATE = "chaturbate"
    STRIPCHAT = "stripchat"
    CAMSODA = "camsoda"
    MYFREECAMS = "myfreecams"
    CAM4 = "cam4"
    BONGACAMS = "bongacams"
    LIVEJASMIN = "livejasmin"
    FLIRT4FREE = "flirt4free"
    XHAMSTERLIVE = "xhamsterlive"
    STREAMATE = "streamate"
    CAMGIRLS = "camgirls"
    IMLIVE = "imlive"
    CAMS = "cams"
    JERKMATE = "jerkmate"
    AMATEUR = "amateur"
    
    @classmethod
    def get_all_sites(cls):
        """ëª¨ë“  ì‚¬ì´íŠ¸ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        return [site.value for site in cls]
    
    @classmethod
    def is_valid_site(cls, site_name):
        """ì£¼ì–´ì§„ ë¬¸ìì—´ì´ ìœ íš¨í•œ ì‚¬ì´íŠ¸ëª…ì¸ì§€ í™•ì¸"""
        return site_name.lower() in cls.get_all_sites()

class PathHistory:
    """ê²½ë¡œ ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, config_file="path_history.json"):
        self.config_file = config_file
        self.history = self.load_history()
    
    def load_history(self):
        """JSON íŒŒì¼ì—ì„œ ê²½ë¡œ ê¸°ë¡ì„ ë¡œë“œ"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"ê²½ë¡œ ê¸°ë¡ ë¡œë“œë¨: {len(data.get('paths', []))}ê°œ ê²½ë¡œ")
                    return data
            else:
                logger.info("ê²½ë¡œ ê¸°ë¡ íŒŒì¼ì´ ì—†ìŒ, ìƒˆë¡œ ìƒì„±")
                return {"paths": [], "last_updated": None}
        except Exception as e:
            logger.error(f"ê²½ë¡œ ê¸°ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {"paths": [], "last_updated": None}
    
    def save_history(self):
        """í˜„ì¬ ê²½ë¡œ ê¸°ë¡ì„ JSON íŒŒì¼ì— ì €ì¥"""
        try:
            self.history["last_updated"] = datetime.now().isoformat()
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
            logger.info(f"ê²½ë¡œ ê¸°ë¡ ì €ì¥ë¨: {self.config_file}")
        except Exception as e:
            logger.error(f"ê²½ë¡œ ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def add_path(self, path):
        """ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ê¸°ë¡ì— ì¶”ê°€"""
        if not path or not os.path.exists(path):
            return False
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        abs_path = os.path.abspath(path)
        
        # ê¸°ì¡´ ê²½ë¡œ ì°¾ê¸°
        existing_path = None
        for item in self.history["paths"]:
            if item["path"] == abs_path:
                existing_path = item
                break
        
        if existing_path:
            # ê¸°ì¡´ ê²½ë¡œ ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰ ì‚¬ìš© ì‹œê°„, ì‚¬ìš© íšŸìˆ˜ ì¦ê°€)
            existing_path["last_used"] = datetime.now().isoformat()
            existing_path["usage_count"] = existing_path.get("usage_count", 0) + 1
            logger.info(f"ê¸°ì¡´ ê²½ë¡œ ì—…ë°ì´íŠ¸: {abs_path} (ì‚¬ìš© íšŸìˆ˜: {existing_path['usage_count']})")
        else:
            # ìƒˆ ê²½ë¡œ ì¶”ê°€
            new_path_info = {
                "path": abs_path,
                "display_name": os.path.basename(abs_path) or abs_path,
                "first_used": datetime.now().isoformat(),
                "last_used": datetime.now().isoformat(),
                "usage_count": 1
            }
            self.history["paths"].append(new_path_info)
            logger.info(f"ìƒˆ ê²½ë¡œ ì¶”ê°€: {abs_path}")
        
        # ì‚¬ìš© íšŸìˆ˜ì™€ ìµœê·¼ ì‚¬ìš© ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        self.history["paths"].sort(key=lambda x: (x.get("usage_count", 0), x.get("last_used", "")), reverse=True)
        
        # ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ ë³´ê´€
        if len(self.history["paths"]) > 20:
            self.history["paths"] = self.history["paths"][:20]
        
        self.save_history()
        return True
    
    def get_paths(self):
        """ì €ì¥ëœ ê²½ë¡œ ëª©ë¡ ë°˜í™˜"""
        return self.history.get("paths", [])
    
    def remove_path(self, path):
        """ê²½ë¡œë¥¼ ê¸°ë¡ì—ì„œ ì œê±°"""
        abs_path = os.path.abspath(path)
        self.history["paths"] = [item for item in self.history["paths"] if item["path"] != abs_path]
        self.save_history()
        logger.info(f"ê²½ë¡œ ì œê±°ë¨: {abs_path}")

class CapacityFinder:
    def __init__(self):
        self.current_path = None
        self.dic_files = {}  # {username: {'total_size': float, 'files': [{'name': str, 'size': float}]}}
        self.window = None  # GUI ìœˆë„ìš° ì°¸ì¡°ë¥¼ ìœ„í•´ ì¶”ê°€
        self.path_history = PathHistory()  # ê²½ë¡œ ê¸°ë¡ ê´€ë¦¬ì ì¶”ê°€
        # ë‚ ì§œ íŒ¨í„´ ì •ì˜ (2025-06-26T15_09_46+09_00 í˜•ì‹)
        self.date_pattern = re.compile(r'\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2}[+-]\d{2}_\d{2}')
        
        # === ë„êµ¬ ê°„ ê°„ë‹¨í•œ ë„¤ë¹„ê²Œì´ì…˜ ì»¨í…ìŠ¤íŠ¸ ===
        self.navigation_context = {
            'selected_user': None,        # í˜„ì¬ ì„ íƒëœ ì‚¬ìš©ì
            'source_tool': None,          # ì¶œë°œì  ë„êµ¬
            'return_callback': None,      # ëŒì•„ê°ˆ ë•Œ í˜¸ì¶œí•  ì½œë°±
        }
        
        # === ì§€ëŠ¥í˜• íë ˆì´ì…˜ ì‹œìŠ¤í…œ ì¶”ê°€ ===
        self.intelligent_system = IntelligentCurationSystem()
        
        logger.info("CapacityFinder ì´ˆê¸°í™” ì™„ë£Œ")
        logger.info("ğŸ§  ì§€ëŠ¥í˜• íë ˆì´ì…˜ ì‹œìŠ¤í…œ ì—°ë™ ì™„ë£Œ (ë‹¤ì–‘ì„± ìœ ì§€ ì ìˆ˜ ë¶„í¬ ì‹œìŠ¤í…œ)")
        
    def format_file_size(self, size_mb):
        """íŒŒì¼ ì‚¬ì´ì¦ˆë¥¼ ì ì ˆí•œ ë‹¨ìœ„(MB/GB)ë¡œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
        if size_mb >= 1024:  # 1GB ì´ìƒ
            size_gb = size_mb / 1024
            return f"{size_gb:.2f} GB"
        else:
            return f"{size_mb:.2f} MB"
        
    def handle_path_confirmation(self, path):
        """GUIì—ì„œ ê²½ë¡œê°€ í™•ì¸ë˜ì—ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜"""
        import time
        start_time = time.time()
        logger.info(f"ê²½ë¡œ í™•ì¸ë¨: {path}")
        logger.info(f"ğŸ“Š ê²½ë¡œ ë¡œë”© ì‹œì‘: {path}")
        
        self.current_path = path
        
        # ê²½ë¡œë¥¼ ê¸°ë¡ì— ì¶”ê°€ (JSONì— ìë™ ì €ì¥)
        if self.path_history.add_path(path):
            logger.info(f"ê²½ë¡œê°€ ê¸°ë¡ì— ì €ì¥ë¨: {path}")
        
        # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
        self.dic_files = {}
        
        # íŒŒì¼ ìš©ëŸ‰ ê³„ì‚°
        logger.debug("íŒŒì¼ ëª©ë¡ ë° ìš©ëŸ‰ ê³„ì‚° ì‹œì‘")
        result_dict = self.listing_files()
        files_processed_time = time.time()
        logger.info(f"â±ï¸ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {files_processed_time - start_time:.2f}ì´ˆ")
        
        if result_dict:
            # GUI ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            self.window.clear_results()
            
            # ìš©ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (í° ê²ƒë¶€í„°)
            sorted_users = sorted(result_dict.items(), key=lambda x: x[1]['total_size'], reverse=True)
            
            # ì „ì²´ íŒŒì¼ í†µê³„ ê³„ì‚°
            total_files_size = sum(user_data['total_size'] for _, user_data in sorted_users)
            total_files_count = sum(len(user_data['files']) for _, user_data in sorted_users)
            formatted_total_size = self.format_file_size(total_files_size)
            
            logger.info(f"íŒŒì¼ ë¶„ì„ ì™„ë£Œ - ì´ {len(sorted_users)}ëª… ì‚¬ìš©ì, ì´ ìš©ëŸ‰: {formatted_total_size}, ì´ íŒŒì¼: {total_files_count}ê°œ")
            
            # ê²°ê³¼ë¥¼ GUIì— í‘œì‹œ (í—¤ë”ë¥¼ ê° ì—´ì— ë§ì¶° í‘œì‹œ)
            self.window.add_header_with_totals("ì‚¬ìš©ìë³„ íŒŒì¼ ìš©ëŸ‰ (ìš©ëŸ‰ í° ìˆœ)", formatted_total_size, total_files_count)
            for username, user_data in sorted_users:
                total_size = user_data['total_size']
                file_count = len(user_data['files'])
                formatted_size = self.format_file_size(total_size)
                
                # ìƒˆë¡œìš´ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ì‚¬ìš©ì ë°ì´í„° ì¶”ê°€
                self.window.add_user_data(username, user_data, formatted_size)
                
                logger.debug(f"ì‚¬ìš©ì: {username}, ì´ ìš©ëŸ‰: {formatted_size}, íŒŒì¼ ìˆ˜: {file_count}")
            
            # CapacityFinder ì¸ìŠ¤í„´ìŠ¤ë¥¼ GUIì— ì„¤ì •í•˜ê³  ëª¨ë¸ ì •ë¦¬ ë²„íŠ¼ í™œì„±í™”
            self.window.set_capacity_finder(self)
            self.window.update_cleanup_button_state()
            
            # ì „ì²´ ë¡œë”© ì™„ë£Œ ì‹œê°„ ì¸¡ì •
            total_time = time.time() - start_time
            logger.info(f"ğŸ¯ ì „ì²´ ê²½ë¡œ ë¡œë”© ì™„ë£Œ: {total_time:.2f}ì´ˆ")
            logger.info(f"   ğŸ“Š íŒŒì¼ ì²˜ë¦¬: {files_processed_time - start_time:.2f}ì´ˆ")
            logger.info(f"   ğŸ–¥ï¸ GUI í‘œì‹œ: {total_time - (files_processed_time - start_time):.2f}ì´ˆ")
        else:
            logger.warning("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.window.add_result_to_list("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.window.update_cleanup_button_state()
            
            # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬ ì‹œê°„ë„ ì¸¡ì •
            total_time = time.time() - start_time
            logger.info(f"ğŸ¯ ê²½ë¡œ ë¡œë”© ì™„ë£Œ (ë¹ˆ ê²°ê³¼): {total_time:.2f}ì´ˆ")
        
    def get_file_size_info(self, file_path, file_name):
        """ë‹¨ì¼ íŒŒì¼ì˜ í¬ê¸° ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ (ë©€í‹°ìŠ¤ë ˆë”©ìš©)"""
        try:
            if os.path.isfile(file_path):
                file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                return [file_name, file_size_mb]
            return None
        except Exception as e:
            logger.error(f"íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {file_path}, ì—ëŸ¬: {e}")
            return None

    def listing_files_capacity(self) -> list:
        """íŒŒì¼ ìš©ëŸ‰ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ë©€í‹°ìŠ¤ë ˆë”© ì§€ì›)"""
        list_files = []
        if self.current_path:
            try:
                import time
                start_time = time.time()
                
                # 1. íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
                logger.info("ğŸ“ íŒŒì¼ ëª©ë¡ ìŠ¤ìº” ì‹œì‘...")
                all_files = os.listdir(self.current_path)
                file_paths = [(os.path.join(self.current_path, file), file) for file in all_files]
                
                scan_time = time.time() - start_time
                logger.info(f"ğŸ“ íŒŒì¼ ëª©ë¡ ìŠ¤ìº” ì™„ë£Œ: {len(file_paths)}ê°œ íŒŒì¼ ë°œê²¬ ({scan_time:.2f}ì´ˆ)")
                
                if not file_paths:
                    return []
                
                # 2. ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸°
                logger.info("ğŸš€ ë©€í‹°ìŠ¤ë ˆë”© íŒŒì¼ í¬ê¸° ë¶„ì„ ì‹œì‘...")
                size_start = time.time()
                
                # ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì„ ê³ ë ¤í•˜ì—¬ ìŠ¤ë ˆë“œ ìˆ˜ ì¡°ì • (ë„ˆë¬´ ë§ìœ¼ë©´ ì˜¤íˆë ¤ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ)
                max_workers = min(20, len(file_paths))  # ìµœëŒ€ 20ê°œ ìŠ¤ë ˆë“œ
                
                with ThreadPoolExecutor(max_workers=max_workers) as executor:
                    # ê° íŒŒì¼ì˜ í¬ê¸°ë¥¼ ë³‘ë ¬ë¡œ ê°€ì ¸ì˜¤ê¸°
                    future_to_file = {
                        executor.submit(self.get_file_size_info, file_path, file_name): file_name
                        for file_path, file_name in file_paths
                    }
                    
                    completed_count = 0
                    log_interval = max(1, len(file_paths) // 10)  # 10% ê°„ê²©ìœ¼ë¡œ ë¡œê·¸
                    
                    for future in as_completed(future_to_file):
                        file_name = future_to_file[future]
                        try:
                            result = future.result()
                            if result is not None:
                                list_files.append(result)
                            
                            completed_count += 1
                            
                            # ì§„í–‰ ìƒí™© ë¡œê·¸ (10% ê°„ê²©)
                            if completed_count % log_interval == 0 or completed_count == len(file_paths):
                                progress = (completed_count / len(file_paths)) * 100
                                elapsed = time.time() - size_start
                                logger.info(f"âš¡ ì§„í–‰ë¥ : {progress:.1f}% ({completed_count}/{len(file_paths)}) - {elapsed:.1f}ì´ˆ")
                        
                        except Exception as e:
                            logger.error(f"íŒŒì¼ í¬ê¸° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {file_name}, ì—ëŸ¬: {e}")
                
                total_time = time.time() - start_time
                size_time = time.time() - size_start
                
                logger.info(f"âœ… íŒŒì¼ ëª©ë¡ ì½ê¸° ì™„ë£Œ: {len(list_files)}ê°œ íŒŒì¼")
                logger.info(f"   ğŸ“Š ì´ ì†Œìš” ì‹œê°„: {total_time:.2f}ì´ˆ")
                logger.info(f"   ğŸ“ íŒŒì¼ ìŠ¤ìº”: {scan_time:.2f}ì´ˆ")
                logger.info(f"   ğŸš€ í¬ê¸° ë¶„ì„: {size_time:.2f}ì´ˆ")
                logger.info(f"   âš¡ ì†ë„ í–¥ìƒ: {max_workers}ê°œ ìŠ¤ë ˆë“œ ì‚¬ìš©")
                
                return list_files
                
            except Exception as e:
                logger.error(f"íŒŒì¼ ëª©ë¡ ì½ê¸° ì˜¤ë¥˜: {e}")
                return []
        else:
            logger.warning("ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
    
    def process_file_name(self, file_info):
        """ë‹¨ì¼ íŒŒì¼ì˜ ì´ë¦„ì„ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜ (ë©€í‹°ìŠ¤ë ˆë”©ìš©)"""
        file_name = file_info[0]
        file_size = file_info[1]
        
        username = self.file_name_handle(file_name)
        if username:
            return {
                'username': username,
                'file_name': file_name,
                'file_size': file_size,
                'success': True
            }
        else:
            return {
                'file_name': file_name,
                'success': False
            }

    def listing_files(self):
        """íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©ìë³„ë¡œ ìš©ëŸ‰ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜ (ë©€í‹°ìŠ¤ë ˆë”© ì§€ì›)"""
        import time
        start_time = time.time()
        
        file_list = self.listing_files_capacity()
        
        if not file_list:
            return {}
        
        parsing_start = time.time()
        logger.info(f"ğŸ” íŒŒì¼ëª… íŒŒì‹± ì‹œì‘: {len(file_list)}ê°œ íŒŒì¼")
        
        parsed_count = 0
        failed_files = []
        
        # íŒŒì¼ ìˆ˜ê°€ ë§ì„ ë•Œë§Œ ë©€í‹°ìŠ¤ë ˆë”© ì‚¬ìš© (ì ì„ ë•ŒëŠ” ì˜¤ë²„í—¤ë“œê°€ ë” í´ ìˆ˜ ìˆìŒ)
        if len(file_list) > 100:
            # ë©€í‹°ìŠ¤ë ˆë”©ìœ¼ë¡œ íŒŒì¼ëª… ì²˜ë¦¬
            max_workers = min(10, len(file_list))  # íŒŒì¼ëª… ì²˜ë¦¬ëŠ” CPU ì‘ì—…ì´ë¼ ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ
            
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_file = {
                    executor.submit(self.process_file_name, file_info): file_info
                    for file_info in file_list
                }
                
                completed_count = 0
                log_interval = max(1, len(file_list) // 10)  # 10% ê°„ê²©ìœ¼ë¡œ ë¡œê·¸
                
                for future in as_completed(future_to_file):
                    file_info = future_to_file[future]
                    try:
                        result = future.result()
                        
                        if result['success']:
                            username = result['username']
                            file_name = result['file_name']
                            file_size = result['file_size']
                            
                            # ì‚¬ìš©ìë³„ ìš©ëŸ‰ ëˆ„ì 
                            if username not in self.dic_files:
                                self.dic_files[username] = {'total_size': 0.0, 'files': []}
                            self.dic_files[username]['total_size'] += file_size
                            self.dic_files[username]['files'].append({'name': file_name, 'size': file_size})
                            parsed_count += 1
                        else:
                            failed_files.append(result['file_name'])
                        
                        completed_count += 1
                        
                        # ì§„í–‰ ìƒí™© ë¡œê·¸
                        if completed_count % log_interval == 0 or completed_count == len(file_list):
                            progress = (completed_count / len(file_list)) * 100
                            elapsed = time.time() - parsing_start
                            logger.info(f"ğŸ” íŒŒì‹± ì§„í–‰ë¥ : {progress:.1f}% ({completed_count}/{len(file_list)}) - {elapsed:.1f}ì´ˆ")
                    
                    except Exception as e:
                        logger.error(f"íŒŒì¼ëª… ì²˜ë¦¬ ì‹¤íŒ¨: {file_info[0]}, ì—ëŸ¬: {e}")
                        failed_files.append(file_info[0])
        
        else:
            # ë‹¨ì¼ìŠ¤ë ˆë“œë¡œ íŒŒì¼ëª… ì²˜ë¦¬ (íŒŒì¼ ìˆ˜ê°€ ì ì„ ë•Œ)
            logger.info("ğŸ“ ë‹¨ì¼ìŠ¤ë ˆë“œ íŒŒì¼ëª… ì²˜ë¦¬ (íŒŒì¼ ìˆ˜ê°€ ì ìŒ)")
            for file_info in file_list:
                file_name = file_info[0]
                file_size = file_info[1]
                
                username = self.file_name_handle(file_name)
                if username:
                    # ì‚¬ìš©ìë³„ ìš©ëŸ‰ ëˆ„ì 
                    if username not in self.dic_files:
                        self.dic_files[username] = {'total_size': 0.0, 'files': []}
                    self.dic_files[username]['total_size'] += file_size
                    self.dic_files[username]['files'].append({'name': file_name, 'size': file_size})
                    parsed_count += 1
                else:
                    failed_files.append(file_name)
        
        parsing_time = time.time() - parsing_start
        total_time = time.time() - start_time
        
        logger.info(f"âœ… íŒŒì¼ ë¶„ì„ ì™„ë£Œ:")
        logger.info(f"   ğŸ“ ì´ íŒŒì¼: {len(file_list)}ê°œ")
        logger.info(f"   ğŸ‘¥ ì¸ì‹ëœ ì‚¬ìš©ì: {len(self.dic_files)}ëª…")
        logger.info(f"   âœ… ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±: {parsed_count}ê°œ")
        logger.info(f"   âŒ íŒŒì‹± ì‹¤íŒ¨: {len(failed_files)}ê°œ")
        logger.info(f"   â±ï¸ íŒŒì‹± ì‹œê°„: {parsing_time:.3f}ì´ˆ")
        logger.info(f"   â±ï¸ ì „ì²´ ì‹œê°„: {total_time:.3f}ì´ˆ")
        
        # ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ ë¡œê·¸ (ë„ˆë¬´ ë§ì§€ ì•Šì„ ë•Œë§Œ)
        if failed_files and len(failed_files) <= 10:
            logger.warning(f"íŒŒì‹± ì‹¤íŒ¨í•œ íŒŒì¼ë“¤: {failed_files}")
        elif failed_files:
            logger.warning(f"íŒŒì‹± ì‹¤íŒ¨í•œ íŒŒì¼ {len(failed_files)}ê°œ (ì¼ë¶€): {failed_files[:5]}...")
        
        return self.dic_files

    def file_name_handle(self, file_name):
        """íŒŒì¼ ì´ë¦„ì„ ì²˜ë¦¬í•´ì„œ ì±„ë„ëª…ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        ë‹¤ì–‘í•œ íŒŒì¼ëª… êµ¬ì¡° ì§€ì›:
        - ì‚¬ì´íŠ¸-ì±„ë„-ë‚ ì§œ
        - ì±„ë„-ì‚¬ì´íŠ¸-ë‚ ì§œ
        - ê¸°íƒ€ ì¡°í•©
        ì˜ˆ: instagram-john_doe-2025-06-26T15_09_46+09_00.txt -> john_doe ë°˜í™˜
        """
        if not file_name:
            return None
            
        try:
            # í™•ì¥ì ì œê±°
            name_without_ext = file_name.split('.')[0] if '.' in file_name else file_name
            
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            date_match = self.date_pattern.search(name_without_ext)
            if not date_match:
                logger.warning(f"ë‚ ì§œ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            date_part = date_match.group()
            date_start = date_match.start()
            
            # ë‚ ì§œ ì´ì „ ë¶€ë¶„ ì¶”ì¶œ
            before_date = name_without_ext[:date_start].rstrip('-')
            
            # '-'ë¡œ ë¶„ë¦¬
            parts = before_date.split('-')
            
            if len(parts) < 2:
                logger.warning(f"íŒŒì¼ëª… êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ: {file_name}")
                return None
            
            # ì‚¬ì´íŠ¸ ì°¾ê¸°
            site_part = None
            channel_parts = []
            
            for i, part in enumerate(parts):
                if SiteType.is_valid_site(part):
                    site_part = part
                    # ì‚¬ì´íŠ¸ê°€ ì•„ë‹Œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ë“¤ì„ ì±„ë„ëª…ìœ¼ë¡œ ê²°í•©
                    channel_parts = parts[:i] + parts[i+1:]
                    break
            
            if not site_part:
                logger.warning(f"ì•Œë ¤ì§„ ì‚¬ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            if not channel_parts:
                logger.warning(f"ì±„ë„ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            # ì±„ë„ëª… ê²°í•© (ì—¬ëŸ¬ ë¶€ë¶„ì´ ìˆì„ ê²½ìš° '-'ë¡œ ë‹¤ì‹œ ê²°í•©)
            channel_name = '-'.join(channel_parts)
            
            logger.debug(f"íŒŒì¼ëª… ì²˜ë¦¬ ì™„ë£Œ: {file_name} -> ì‚¬ì´íŠ¸: {site_part}, ì±„ë„: {channel_name}, ë‚ ì§œ: {date_part}")
            return channel_name
                    
        except Exception as e:
            logger.error(f"íŒŒì¼ëª… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return None

    def extract_date_from_filename(self, file_name):
        """íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        try:
            date_match = self.date_pattern.search(file_name)
            if date_match:
                date_str = date_match.group()
                # 2025-06-26T15_09_46+09_00 -> datetime ë³€í™˜
                file_date = datetime.fromisoformat(date_str.replace('_', ':'))
                return file_date
        except Exception as e:
            logger.error(f"ë‚ ì§œ ì¶”ì¶œ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
        return None

    def select_representative_samples(self, files):
        """ë” ëŒ€í‘œì„± ìˆëŠ” ìƒ˜í”Œ ì„ íƒ"""
        if len(files) <= 5:
            return files  # íŒŒì¼ ì ìœ¼ë©´ ë‹¤ ë³´ì—¬ì£¼ê¸°
        
        samples = []
        
        # íŒŒì¼ë“¤ì„ ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        files_with_dates = []
        for file_info in files:
            file_date = self.extract_date_from_filename(file_info['name'])
            if file_date:
                files_with_dates.append({'file': file_info, 'date': file_date})
        
        if not files_with_dates:
            return files[:5]  # ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ì‹œ ì²« 5ê°œ
        
        files_with_dates.sort(key=lambda x: x['date'])
        sorted_files = [item['file'] for item in files_with_dates]
        
        # 1. ê°€ì¥ ìµœê·¼ íŒŒì¼
        samples.append(sorted_files[-1])
        
        # 2. ê°€ì¥ í° íŒŒì¼  
        largest_file = max(files, key=lambda x: x['size'])
        if largest_file not in samples:
            samples.append(largest_file)
        
        # 3. ì‹œê°„ëŒ€ë³„ ë¶„ì‚° ìƒ˜í”Œ (ì²˜ìŒ/ì¤‘ê°„)
        if len(sorted_files) > 2:
            # ì²« ê¸°ë¡
            if sorted_files[0] not in samples:
                samples.append(sorted_files[0])
            # ì¤‘ê°„
            middle_file = sorted_files[len(sorted_files)//2]
            if middle_file not in samples:
                samples.append(middle_file)
        
        # 4. ë‚¨ì€ ìë¦¬ì— ë‹¤ë¥¸ íŒŒì¼ë“¤
        for file_info in files:
            if file_info not in samples and len(samples) < 5:
                samples.append(file_info)
        
        return samples[:5]  # ìµœëŒ€ 5ê°œ

    def create_decision_list(self):
        """ê²°ì •í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬"""
        if not self.dic_files:
            logger.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ìš©ëŸ‰ í° ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = sorted(
            self.dic_files.items(), 
            key=lambda x: x[1]['total_size'], 
            reverse=True
        )
        
        decision_list = []
        for username, data in sorted_models:
            # ëŒ€í‘œ íŒŒì¼ë“¤ ì„ íƒ
            sample_files = self.select_representative_samples(data['files'])
            
            decision_list.append({
                'username': username,
                'total_size': data['total_size'],
                'file_count': len(data['files']),
                'sample_files': sample_files,
                'potential_savings': data['total_size']  # ì‚­ì œì‹œ ì ˆì•½ ìš©ëŸ‰
            })
        
        return decision_list

    def compare_user_sites(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ì‚¬ì´íŠ¸ë³„ íŒŒì¼ ë¹„êµ ë° ì¤‘ë³µ ì œê±° ì¶”ì²œ
        
        Args:
            username: ë¹„êµí•  ì‚¬ìš©ìëª…
            
        Returns:
            dict: {
                'files_to_delete': [{'name': str, 'size': float, 'site': str, 'date': str}],
                'total_savings': float,
                'username': str,
                'comparison_results': [dict]  # ë¹„êµ ê²°ê³¼ ìƒì„¸
            }
        """
        if username not in self.dic_files:
            return None
        
        user_files = self.dic_files[username]['files']
        
        # íŒŒì¼ë“¤ì„ ì‚¬ì´íŠ¸ë³„, ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        date_site_groups = {}  # {date: {site: [files]}}
        
        for file_info in user_files:
            file_name = file_info['name']
            file_size = file_info['size']
            
            # íŒŒì¼ëª…ì—ì„œ ì‚¬ì´íŠ¸ì™€ ë‚ ì§œ ì¶”ì¶œ
            site, date_str = self.extract_site_and_date(file_name)
            if not site or not date_str:
                continue
            
            if date_str not in date_site_groups:
                date_site_groups[date_str] = {}
            
            if site not in date_site_groups[date_str]:
                date_site_groups[date_str][site] = []
            
            date_site_groups[date_str][site].append({
                'name': file_name,
                'size': file_size,
                'site': site,
                'date': date_str
            })
        
        # ê°™ì€ ë‚ ì§œì— ì—¬ëŸ¬ ì‚¬ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš° ìš©ëŸ‰ ë¹„êµ
        files_to_delete = []
        comparison_results = []
        total_savings = 0
        
        for date_str, sites in date_site_groups.items():
            if len(sites) <= 1:
                continue  # ì‚¬ì´íŠ¸ê°€ í•˜ë‚˜ë¿ì´ë©´ ë¹„êµí•  í•„ìš” ì—†ìŒ
            
            # ì‚¬ì´íŠ¸ë³„ ì´ ìš©ëŸ‰ ê³„ì‚°
            site_totals = {}
            for site, files in sites.items():
                site_totals[site] = sum(f['size'] for f in files)
            
            # ê°€ì¥ í° ìš©ëŸ‰ì˜ ì‚¬ì´íŠ¸ ì°¾ê¸°
            max_site = max(site_totals.items(), key=lambda x: x[1])
            max_site_name = max_site[0]
            max_size = max_site[1]
            
            # ë‹¤ë¥¸ ì‚¬ì´íŠ¸ë“¤ì˜ íŒŒì¼ì„ ì‚­ì œ ëŒ€ìƒìœ¼ë¡œ ì¶”ê°€
            comparison_result = {
                'date': date_str,
                'sites': {},
                'keep_site': max_site_name,
                'delete_sites': []
            }
            
            for site, files in sites.items():
                site_total = site_totals[site]
                comparison_result['sites'][site] = {
                    'files': files,
                    'total_size': site_total,
                    'file_count': len(files)
                }
                
                if site != max_site_name:
                    # ì‘ì€ ìš©ëŸ‰ì˜ ì‚¬ì´íŠ¸ íŒŒì¼ë“¤ì„ ì‚­ì œ ëŒ€ìƒì— ì¶”ê°€
                    for file_info in files:
                        files_to_delete.append(file_info)
                        total_savings += file_info['size']
                    comparison_result['delete_sites'].append(site)
            
            comparison_results.append(comparison_result)
        
        return {
            'files_to_delete': files_to_delete,
            'total_savings': total_savings,
            'username': username,
            'comparison_results': comparison_results
        }
    
    def extract_site_and_date(self, file_name):
        """íŒŒì¼ëª…ì—ì„œ ì‚¬ì´íŠ¸ì™€ ë‚ ì§œë¥¼ ì¶”ì¶œ
        
        Args:
            file_name: íŒŒì¼ëª…
            
        Returns:
            tuple: (site, date_str) ë˜ëŠ” (None, None)
        """
        if not file_name:
            return None, None
            
        try:
            # í™•ì¥ì ì œê±°
            name_without_ext = file_name.split('.')[0] if '.' in file_name else file_name
            
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            date_match = self.date_pattern.search(name_without_ext)
            if not date_match:
                return None, None
            
            date_part = date_match.group()
            date_start = date_match.start()
            
            # ë‚ ì§œ ì´ì „ ë¶€ë¶„ ì¶”ì¶œ
            before_date = name_without_ext[:date_start].rstrip('-')
            
            # '-'ë¡œ ë¶„ë¦¬
            parts = before_date.split('-')
            
            if len(parts) < 2:
                return None, None
            
            # ì‚¬ì´íŠ¸ ì°¾ê¸°
            for part in parts:
                if SiteType.is_valid_site(part):
                    # ë‚ ì§œì—ì„œ ì‹œê°„ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì„œ ë‚ ì§œë¡œ ë³€í™˜ (2025-06-26 í˜•ì‹)
                    date_only = date_part.split('T')[0] if 'T' in date_part else date_part
                    return part, date_only
            
            return None, None
                    
        except Exception as e:
            logger.error(f"ì‚¬ì´íŠ¸/ë‚ ì§œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return None, None

    def get_available_users(self):
        """ë¶„ì„ëœ ì‚¬ìš©ì ëª©ë¡ ë°˜í™˜"""
        if not self.dic_files:
            return []
        return list(self.dic_files.keys())

    def calculate_file_score(self, file_info, user_files):
        """íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        
        Args:
            file_info: ê°œë³„ íŒŒì¼ ì •ë³´
            user_files: í•´ë‹¹ ì‚¬ìš©ìì˜ ì „ì²´ íŒŒì¼ ëª©ë¡
            
        Returns:
            float: 0.0 ~ 1.0 ì‚¬ì´ì˜ ì ìˆ˜
        """
        file_name = file_info['name']
        file_size = file_info['size']
        
        # ê¸°ë³¸ ì ìˆ˜ êµ¬ì„± ìš”ì†Œë“¤
        size_score = 0.0
        rarity_score = 0.0
        date_score = 0.0
        
        try:
            # 1. íŒŒì¼ í¬ê¸° ì ìˆ˜ (60% ê°€ì¤‘ì¹˜) - ì¦ê°€
            all_sizes = [f['size'] for f in user_files]
            if all_sizes:
                max_size = max(all_sizes)
                min_size = min(all_sizes)
                if max_size > min_size:
                    # í¬ê¸° ì ìˆ˜ë¥¼ ë” ê´€ëŒ€í•˜ê²Œ ê³„ì‚° (ìƒìœ„ 30% ì´ìƒì´ë©´ 0.8+ ì ìˆ˜)
                    normalized_score = (file_size - min_size) / (max_size - min_size)
                    # ì œê³±ê·¼ ì ìš©í•´ì„œ ì¤‘ê°„ê°’ë“¤ë„ ë” ë†’ì€ ì ìˆ˜ ë°›ë„ë¡
                    size_score = min(normalized_score ** 0.5, 1.0)
                else:
                    size_score = 1.0
            
            # 2. í¬ê·€ì„± ì ìˆ˜ (25% ê°€ì¤‘ì¹˜) - ì¦ê°€
            file_date = self.extract_date_from_filename(file_name)
            if file_date:
                # ê°™ì€ ë‚ ì§œì˜ íŒŒì¼ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ í¬ê·€í•¨
                same_date_count = 0
                for f in user_files:
                    f_date = self.extract_date_from_filename(f['name'])
                    if f_date and f_date.date() == file_date.date():
                        same_date_count += 1
                
                if same_date_count <= 1:
                    rarity_score = 1.0
                elif same_date_count <= 2:
                    rarity_score = 0.9
                elif same_date_count <= 3:
                    rarity_score = 0.8
                elif same_date_count <= 5:
                    rarity_score = 0.7
                else:
                    rarity_score = 0.5
            else:
                # ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼ì€ ì¤‘ê°„ ì ìˆ˜
                rarity_score = 0.6
            
            # 3. ë‚ ì§œ ì ìˆ˜ (15% ê°€ì¤‘ì¹˜) - ì¦ê°€, ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            if file_date:
                all_dates = []
                for f in user_files:
                    f_date = self.extract_date_from_filename(f['name'])
                    if f_date:
                        all_dates.append(f_date)
                
                if all_dates:
                    all_dates.sort()
                    oldest = all_dates[0]
                    newest = all_dates[-1]
                    
                    if newest > oldest:
                        total_days = (newest - oldest).days
                        file_days = (file_date - oldest).days
                        date_score = file_days / total_days if total_days > 0 else 1.0
                    else:
                        date_score = 1.0
                else:
                    date_score = 0.8
            else:
                # ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼ì€ ì¤‘ê°„ ì ìˆ˜
                date_score = 0.5
        
        except Exception as e:
            logger.error(f"ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return 0.6  # ê¸°ë³¸ê°’ì„ 0.6ìœ¼ë¡œ ìƒí–¥
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ì‹œê°„ ì ìˆ˜ ì œê±°, ë‹¤ë¥¸ ìš”ì†Œë“¤ ê°€ì¤‘ì¹˜ ì¦ê°€)
        final_score = (size_score * 0.6 + rarity_score * 0.25 + date_score * 0.15)
        
        # ì¶”ê°€ ë³´ë„ˆìŠ¤: ë§¤ìš° í° íŒŒì¼ì—ê²Œ ë³´ë„ˆìŠ¤ ì ìˆ˜
        if all_sizes:
            size_percentile = (file_size - min(all_sizes)) / (max(all_sizes) - min(all_sizes)) if max(all_sizes) > min(all_sizes) else 1.0
            if size_percentile >= 0.9:  # ìƒìœ„ 10% í¬ê¸°
                final_score = min(final_score + 0.1, 1.0)
            elif size_percentile >= 0.8:  # ìƒìœ„ 20% í¬ê¸°
                final_score = min(final_score + 0.05, 1.0)
        
        return min(max(final_score, 0.0), 1.0)  # 0.0 ~ 1.0 ì‚¬ì´ë¡œ í´ë¨í•‘

    def get_user_files_with_scores(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ íŒŒì¼ë“¤ì„ ì ìˆ˜ì™€ í•¨ê»˜ ë°˜í™˜
        
        Args:
            username: ì‚¬ìš©ìëª…
            
        Returns:
            list: [{'name': str, 'size': float, 'score': float, 'rank': int}, ...]
        """
        if username not in self.dic_files:
            return []
        
        user_files = self.dic_files[username]['files']
        
        # ê° íŒŒì¼ì— ì ìˆ˜ ì¶”ê°€
        files_with_scores = []
        for file_info in user_files:
            score = self.calculate_file_score(file_info, user_files)
            files_with_scores.append({
                'name': file_info['name'],
                'size': file_info['size'],
                'score': score,
                'rank': 0  # ë‚˜ì¤‘ì— ì„¤ì •
            })
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ë¶€í„°)
        files_with_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # ìˆœìœ„ ì„¤ì •
        for i, file_info in enumerate(files_with_scores):
            file_info['rank'] = i + 1
        
        return files_with_scores

    def get_selection_candidates(self, username, top_n=50):
        """ì„ ë³„ í›„ë³´ íŒŒì¼ë“¤ ë°˜í™˜ (ìƒìœ„ Nê°œ) - ì§€ëŠ¥í˜• ë³µí•©ì ìˆ˜ ì‹œìŠ¤í…œ ì ìš©
        
        Args:
            username: ì‚¬ìš©ìëª…
            top_n: í›„ë³´ë¡œ ì„ íƒí•  íŒŒì¼ ìˆ˜
            
        Returns:
            dict: {
                'candidates': list,  # ì„ ë³„ í›„ë³´ íŒŒì¼ë“¤
                'excluded': list,    # ìë™ ì œì™¸ëœ íŒŒì¼ë“¤
                'total_files': int,  # ì „ì²´ íŒŒì¼ ìˆ˜
                'username': str
            }
        """
        if username not in self.dic_files:
            return None
        
        user_data = self.dic_files[username]
        files = user_data['files']
        
        # ì§€ëŠ¥í˜• ë³µí•© ì ìˆ˜ë¥¼ ì‚¬ìš©í•œ íŒŒì¼ ë¶„ì„
        files_with_scores = []
        for file_info in files:
            # ì§€ëŠ¥í˜• ì‹œìŠ¤í…œì˜ ë³µí•© ì ìˆ˜ ê³„ì‚° (íŒŒì¼ì ìˆ˜ + ë ˆì´íŒ…ì ìˆ˜)
            score_data = self.intelligent_system.calculate_composite_score(username, file_info, files)
            files_with_scores.append({
                'name': file_info['name'],
                'size': file_info['size'],
                'score': score_data['composite_score'],  # ë³µí•© ì ìˆ˜ ì‚¬ìš©
                'file_score': score_data['file_score'],
                'rating_score': score_data['rating_score'],
                'rank': 0  # ë‚˜ì¤‘ì— ì„¤ì •
            })
        
        # ë³µí•© ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ë¶€í„°)
        files_with_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # ìˆœìœ„ ì„¤ì •
        for i, file_info in enumerate(files_with_scores):
            file_info['rank'] = i + 1
        
        total_files = len(files_with_scores)
        
        # ìƒìœ„ Nê°œë¥¼ í›„ë³´ë¡œ ì„ íƒ
        top_n = min(top_n, total_files)
        candidates = files_with_scores[:top_n]
        excluded = files_with_scores[top_n:]
        
        logger.info(f"ğŸ¯ ì„ ë³„ í›„ë³´ ìƒì„±: {username} - ì´ {total_files}ê°œ ì¤‘ ìƒìœ„ {top_n}ê°œ ì„ íƒ (ì§€ëŠ¥í˜• ë³µí•©ì ìˆ˜ ì ìš©)")
        
        return {
            'candidates': candidates,
            'excluded': excluded,
            'total_files': total_files,
            'username': username
        }
    
    # === ì§€ëŠ¥í˜• íë ˆì´ì…˜ ì‹œìŠ¤í…œ í†µí•© ë©”ì„œë“œë“¤ ===
    
    def get_intelligent_deletion_analysis(self, target_savings_gb=10):
        """ì§€ëŠ¥í˜• ì‚­ì œ ë¶„ì„ - ë ˆì´íŒ… ê¸°ë°˜ ìë™ ì¶”ì²œ"""
        logger.info(f"ğŸ§  ì§€ëŠ¥í˜• ì‚­ì œ ë¶„ì„ ì‹œì‘ (ëª©í‘œ: {target_savings_gb}GB ì ˆì•½)")
        
        # ìë™ ì‚­ì œ ì¶”ì²œ
        suggestions = self.intelligent_system.get_auto_deletion_suggestions(self, target_savings_gb)
        
        # ì‚¬ìš©ìë³„ ì •ë¦¬ ì „ëµ ë¶„ì„
        user_strategies = {}
        for username in self.dic_files.keys():
            strategy = self.intelligent_system.get_user_cleanup_analysis(username)
            if strategy:
                user_strategies[username] = strategy
        
        # í†µê³„ ê³„ì‚°
        total_files = sum(len(data['files']) for data in self.dic_files.values())
        suggested_count = suggestions['files_count']
        suggested_savings = suggestions['total_savings_gb']
        
        analysis_result = {
            'suggestions': suggestions,
            'user_strategies': user_strategies,
            'statistics': {
                'total_files': total_files,
                'suggested_files': suggested_count,
                'suggested_savings_gb': suggested_savings,
                'efficiency_ratio': suggested_count / total_files if total_files > 0 else 0
            }
        }
        
        logger.info(f"âœ… ë¶„ì„ ì™„ë£Œ: {suggested_count}ê°œ íŒŒì¼, {suggested_savings:.2f}GB ì ˆì•½ ê°€ëŠ¥")
        return analysis_result
    
    def get_user_intelligence_report(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ì§€ëŠ¥í˜• ë¶„ì„ ë¦¬í¬íŠ¸"""
        if username not in self.dic_files:
            return None
        
        user_data = self.dic_files[username]
        files = user_data['files']
        
        # ê° íŒŒì¼ì˜ ë³µí•© ì ìˆ˜ ê³„ì‚°
        scored_files = []
        for file_info in files:
            score_data = self.intelligent_system.calculate_composite_score(username, file_info, files)
            scored_files.append({
                'name': file_info['name'],
                'size': file_info['size'],
                'composite_score': score_data['composite_score'],
                'file_score': score_data['file_score'],
                'rating_score': score_data['rating_score']
            })
        
        # ì ìˆ˜ë³„ ì •ë ¬
        scored_files.sort(key=lambda x: x['composite_score'], reverse=True)
        
        # í†µê³„ ê³„ì‚° (ë‹¤ì–‘ì„± ìœ ì§€ ê¸°ì¤€)
        high_quality = [f for f in scored_files if f['composite_score'] >= 0.7]   # 0.8 â†’ 0.7
        medium_quality = [f for f in scored_files if 0.3 <= f['composite_score'] < 0.7]  # 0.2~0.8 â†’ 0.3~0.7
        low_quality = [f for f in scored_files if f['composite_score'] < 0.3]     # 0.2 â†’ 0.3
        
        # ì‚¬ìš©ì ì •ë¦¬ ì „ëµ
        cleanup_strategy = self.intelligent_system.get_user_cleanup_analysis(username)
        
        return {
            'username': username,
            'files': scored_files,
            'quality_breakdown': {
                'high_quality': len(high_quality),
                'medium_quality': len(medium_quality),
                'low_quality': len(low_quality)
            },
            'cleanup_strategy': cleanup_strategy,
            'total_size': user_data['total_size'],
            'file_count': len(files)
        }
    
    def get_priority_deletion_list(self, count_limit=100, balanced_mode=False):
        """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ì‚­ì œ ë¦¬ìŠ¤íŠ¸ (ì „ì²´ ë¶„ì„)
        
        Args:
            count_limit: í‘œì‹œí•  íŒŒì¼ ìˆ˜
            balanced_mode: ê· ë“± ë¶„ë°° ëª¨ë“œ (ê° ì‚¬ìš©ìë³„ë¡œ ê³¨ê³ ë£¨ ì„ íƒ)
        """
        logger.info(f"ğŸ¯ ìš°ì„ ìˆœìœ„ ì‚­ì œ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ìƒìœ„ {count_limit}ê°œ, ê· ë“±ëª¨ë“œ: {balanced_mode})")
        
        priority_list = self.intelligent_system.get_deletion_priority_list(self)
        
        if balanced_mode:
            # ê· ë“± ë¶„ë°° ëª¨ë“œ: ê° ì‚¬ìš©ìë³„ë¡œ ê³¨ê³ ë£¨ ì„ íƒ
            top_priorities = self._get_balanced_priority_list(priority_list, count_limit)
        else:
            # ê¸°ë³¸ ëª¨ë“œ: ì ìˆ˜ ë‚®ì€ ìˆœìœ¼ë¡œ ìƒìœ„ Nê°œ
            top_priorities = priority_list[:count_limit]
        
        # ì‚¬ìš©ìë³„ í†µê³„
        user_stats = {}
        for file_data in top_priorities:
            username = file_data['username']
            if username not in user_stats:
                user_stats[username] = {'count': 0, 'size': 0}
            user_stats[username]['count'] += 1
            user_stats[username]['size'] += file_data['size']
        
        total_savings = sum(f['size'] for f in top_priorities)
        
        return {
            'priority_files': top_priorities,
            'user_breakdown': user_stats,
            'total_savings_gb': total_savings / 1024,
            'file_count': len(top_priorities),
            'balanced_mode': balanced_mode
        }
    
    def _get_balanced_priority_list(self, priority_list, count_limit):
        """ê· ë“± ë¶„ë°° ë°©ì‹ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ ë¦¬ìŠ¤íŠ¸ ìƒì„±"""
        # ì‚¬ìš©ìë³„ë¡œ íŒŒì¼ ê·¸ë£¹í™”
        user_files = {}
        for file_data in priority_list:
            username = file_data['username']
            if username not in user_files:
                user_files[username] = []
            user_files[username].append(file_data)
        
        total_users = len(user_files)
        if total_users == 0:
            return []
        
        # ì‚¬ìš©ìë³„ ê¸°ë³¸ í• ë‹¹ëŸ‰ ê³„ì‚°
        base_per_user = max(1, count_limit // total_users)  # ìµœì†Œ 1ê°œì”©
        remaining = count_limit - (base_per_user * total_users)
        
        balanced_list = []
        user_counts = {}
        
        # 1ë‹¨ê³„: ê° ì‚¬ìš©ìë³„ë¡œ ê¸°ë³¸ í• ë‹¹ëŸ‰ë§Œí¼ ì„ íƒ
        for username, files in user_files.items():
            selected_count = min(base_per_user, len(files))
            balanced_list.extend(files[:selected_count])
            user_counts[username] = selected_count
        
        # 2ë‹¨ê³„: ë‚¨ì€ ìŠ¬ë¡¯ì„ íŒŒì¼ì´ ë§ì€ ì‚¬ìš©ì ìˆœìœ¼ë¡œ ë°°ë¶„
        if remaining > 0:
            # ì‚¬ìš©ìë³„ ë‚¨ì€ íŒŒì¼ ìˆ˜ ê³„ì‚°
            remaining_files = []
            for username, files in user_files.items():
                used_count = user_counts[username]
                if used_count < len(files):
                    # (ë‚¨ì€ íŒŒì¼ ìˆ˜, ì‚¬ìš©ìëª…, íŒŒì¼ ë¦¬ìŠ¤íŠ¸)
                    remaining_files.append((len(files) - used_count, username, files[used_count:]))
            
            # ë‚¨ì€ íŒŒì¼ì´ ë§ì€ ì‚¬ìš©ì ìˆœìœ¼ë¡œ ì •ë ¬
            remaining_files.sort(key=lambda x: x[0], reverse=True)
            
            # ë‚¨ì€ ìŠ¬ë¡¯ ë°°ë¶„
            for remaining_count, username, files in remaining_files:
                if remaining <= 0:
                    break
                
                additional = min(remaining, remaining_count, 10)  # í•œ ì‚¬ìš©ìë‹¹ ìµœëŒ€ 10ê°œ ì¶”ê°€
                balanced_list.extend(files[:additional])
                remaining -= additional
        
        # ìµœì¢…ì ìœ¼ë¡œ ì ìˆ˜ìˆœìœ¼ë¡œ ì •ë ¬
        balanced_list.sort(key=lambda x: x['composite_score'])
        
        logger.info(f"ê· ë“± ë¶„ë°° ì™„ë£Œ: {len(balanced_list)}ê°œ íŒŒì¼, {len(user_counts)}ëª… ì‚¬ìš©ì")
        
        return balanced_list[:count_limit]
    
    def execute_intelligent_cleanup(self, analysis_result, confirm_callback=None):
        """ì§€ëŠ¥í˜• ì •ë¦¬ ì‹¤í–‰"""
        suggested_files = analysis_result['suggestions']['suggested_files']
        
        if not suggested_files:
            logger.warning("ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # í™•ì¸ ì½œë°±ì´ ìˆìœ¼ë©´ í˜¸ì¶œ
        if confirm_callback:
            if not confirm_callback(suggested_files):
                logger.info("ì‚¬ìš©ìê°€ ì§€ëŠ¥í˜• ì •ë¦¬ë¥¼ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
                return False
        
        # íŒŒì¼ ì‚­ì œ ì‹¤í–‰
        deleted_files = []
        deleted_size = 0
        
        for file_data in suggested_files:
            file_path = os.path.join(self.current_path, file_data['name'])
            
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
                    deleted_files.append(file_data)
                    deleted_size += file_data['size']
                    logger.debug(f"ì‚­ì œ ì™„ë£Œ: {file_data['name']}")
                else:
                    logger.warning(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_path}")
            except Exception as e:
                logger.error(f"íŒŒì¼ ì‚­ì œ ì˜¤ë¥˜: {file_path}, ì—ëŸ¬: {e}")
        
        # ì‚­ì œ ê²°ê³¼ í†µê³„
        deleted_size_gb = deleted_size / 1024
        logger.info(f"ğŸ¯ ì§€ëŠ¥í˜• ì •ë¦¬ ì™„ë£Œ: {len(deleted_files)}ê°œ íŒŒì¼, {deleted_size_gb:.2f}GB ì ˆì•½")
        
        return {
            'deleted_files': deleted_files,
            'deleted_count': len(deleted_files),
            'deleted_size_gb': deleted_size_gb,
            'success': True
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜ì—ì„œ GUI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    app = QApplication(sys.argv)
    
    # CapacityFinder ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    finder = CapacityFinder()
    
    # GUI ìƒì„± ì‹œ ì½œë°± í•¨ìˆ˜ì™€ ê²½ë¡œ ê¸°ë¡ ì „ë‹¬
    finder.window = MainWindow(
        on_path_confirmed=finder.handle_path_confirmation,
        path_history=finder.path_history
    )
    finder.window.show()
    
    sys.exit(app.exec_())

if __name__ == '__main__':
    main()
