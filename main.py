#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from gui import MainWindow
import sys
import os
import re
import json
import logging
from datetime import datetime
from enum import Enum
from PyQt5.QtWidgets import QApplication

# ë¡œê·¸ ì„¤ì • í•¨ìˆ˜
def setup_logging():
    """ë¡œê·¸ ì„¤ì •ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    log_dir = "logs"
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    
    # ë¡œê·¸ íŒŒì¼ëª… (ë‚ ì§œ í¬í•¨)
    log_filename = os.path.join(log_dir, f"capacity_finder_{datetime.now().strftime('%Y%m%d')}.log")
    
    # ë¡œê·¸ í¬ë§· ì„¤ì • (íŒŒì¼ëª…, í•¨ìˆ˜ëª…, ë¼ì¸ ë²ˆí˜¸ í¬í•¨)
    log_format = "%(asctime)s - %(levelname)s - [%(filename)s:%(funcName)s:%(lineno)d] - %(message)s"
    
    # ë¡œê·¸ ì„¤ì • - ëª¨ë“  ë ˆë²¨ ì¶œë ¥ (DEBUG í¬í•¨)
    logging.basicConfig(
        level=logging.DEBUG,
        format=log_format,
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),  # íŒŒì¼ ì¶œë ¥
            logging.StreamHandler()  # ì½˜ì†” ì¶œë ¥
        ]
    )
    
    # ë¡œê±° ë°˜í™˜
    return logging.getLogger(__name__)

# ë¡œê·¸ ì„¤ì • ì´ˆê¸°í™”
logger = setup_logging()

# ë‹¤ë¥¸ íŒŒì¼ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë¡œê·¸ ì„¤ì • í•¨ìˆ˜ ì œê³µ
def get_logger(module_name):
    """ë‹¤ë¥¸ ëª¨ë“ˆì—ì„œ ë¡œê±°ë¥¼ ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©"""
    return logging.getLogger(module_name)

class SiteType(Enum):
    """ì§€ì›í•˜ëŠ” ì„±ì¸ í”Œë«í¼ ëª©ë¡"""
    CHATURBATE = "chaturbate"
    STRIPCHAT = "stripchat"
    CAMSODA = "camsoda"
    MYFREECAMS = "myfreecams"
    CAM4 = "cam4"
    BONGACAMS = "bongacams"
    LIVEJASMIN = "livejasmin"
    FLIRT4FREE = "flirt4free"
    XHAMSTERLIVE = "xhamsterlive"
    STREAMATE = "streamate"
    CAMGIRLS = "camgirls"
    IMLIVE = "imlive"
    CAMS = "cams"
    JERKMATE = "jerkmate"
    AMATEUR = "amateur"
    
    @classmethod
    def get_all_sites(cls):
        """ëª¨ë“  ì‚¬ì´íŠ¸ëª…ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
        return [site.value for site in cls]
    
    @classmethod
    def is_valid_site(cls, site_name):
        """ì£¼ì–´ì§„ ë¬¸ìì—´ì´ ìœ íš¨í•œ ì‚¬ì´íŠ¸ëª…ì¸ì§€ í™•ì¸"""
        return site_name.lower() in cls.get_all_sites()

class PathHistory:
    """ê²½ë¡œ ê¸°ë¡ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, config_file="path_history.json"):
        self.config_file = config_file
        self.history = self.load_history()
    
    def load_history(self):
        """JSON íŒŒì¼ì—ì„œ ê²½ë¡œ ê¸°ë¡ì„ ë¡œë“œ"""
        try:
            if os.path.exists(self.config_file):
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    logger.info(f"ê²½ë¡œ ê¸°ë¡ ë¡œë“œë¨: {len(data.get('paths', []))}ê°œ ê²½ë¡œ")
                    return data
            else:
                logger.info("ê²½ë¡œ ê¸°ë¡ íŒŒì¼ì´ ì—†ìŒ, ìƒˆë¡œ ìƒì„±")
                return {"paths": [], "last_updated": None}
        except Exception as e:
            logger.error(f"ê²½ë¡œ ê¸°ë¡ ë¡œë“œ ì˜¤ë¥˜: {e}")
            return {"paths": [], "last_updated": None}
    
    def save_history(self):
        """í˜„ì¬ ê²½ë¡œ ê¸°ë¡ì„ JSON íŒŒì¼ì— ì €ì¥"""
        try:
            self.history["last_updated"] = datetime.now().isoformat()
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, ensure_ascii=False, indent=2)
            logger.info(f"ê²½ë¡œ ê¸°ë¡ ì €ì¥ë¨: {self.config_file}")
        except Exception as e:
            logger.error(f"ê²½ë¡œ ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    def add_path(self, path):
        """ìƒˆë¡œìš´ ê²½ë¡œë¥¼ ê¸°ë¡ì— ì¶”ê°€"""
        if not path or not os.path.exists(path):
            return False
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        abs_path = os.path.abspath(path)
        
        # ê¸°ì¡´ ê²½ë¡œ ì°¾ê¸°
        existing_path = None
        for item in self.history["paths"]:
            if item["path"] == abs_path:
                existing_path = item
                break
        
        if existing_path:
            # ê¸°ì¡´ ê²½ë¡œ ì—…ë°ì´íŠ¸ (ë§ˆì§€ë§‰ ì‚¬ìš© ì‹œê°„, ì‚¬ìš© íšŸìˆ˜ ì¦ê°€)
            existing_path["last_used"] = datetime.now().isoformat()
            existing_path["usage_count"] = existing_path.get("usage_count", 0) + 1
            logger.info(f"ê¸°ì¡´ ê²½ë¡œ ì—…ë°ì´íŠ¸: {abs_path} (ì‚¬ìš© íšŸìˆ˜: {existing_path['usage_count']})")
        else:
            # ìƒˆ ê²½ë¡œ ì¶”ê°€
            new_path_info = {
                "path": abs_path,
                "display_name": os.path.basename(abs_path) or abs_path,
                "first_used": datetime.now().isoformat(),
                "last_used": datetime.now().isoformat(),
                "usage_count": 1
            }
            self.history["paths"].append(new_path_info)
            logger.info(f"ìƒˆ ê²½ë¡œ ì¶”ê°€: {abs_path}")
        
        # ì‚¬ìš© íšŸìˆ˜ì™€ ìµœê·¼ ì‚¬ìš© ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬
        self.history["paths"].sort(key=lambda x: (x.get("usage_count", 0), x.get("last_used", "")), reverse=True)
        
        # ìµœëŒ€ 20ê°œê¹Œì§€ë§Œ ë³´ê´€
        if len(self.history["paths"]) > 20:
            self.history["paths"] = self.history["paths"][:20]
        
        self.save_history()
        return True
    
    def get_paths(self):
        """ì €ì¥ëœ ê²½ë¡œ ëª©ë¡ ë°˜í™˜"""
        return self.history.get("paths", [])
    
    def remove_path(self, path):
        """ê²½ë¡œë¥¼ ê¸°ë¡ì—ì„œ ì œê±°"""
        abs_path = os.path.abspath(path)
        self.history["paths"] = [item for item in self.history["paths"] if item["path"] != abs_path]
        self.save_history()
        logger.info(f"ê²½ë¡œ ì œê±°ë¨: {abs_path}")

class CapacityFinder:
    def __init__(self):
        self.current_path = None
        self.dic_files = {}  # {username: {'total_size': float, 'files': [{'name': str, 'size': float}]}}
        self.window = None  # GUI ìœˆë„ìš° ì°¸ì¡°ë¥¼ ìœ„í•´ ì¶”ê°€
        self.path_history = PathHistory()  # ê²½ë¡œ ê¸°ë¡ ê´€ë¦¬ì ì¶”ê°€
        # ë‚ ì§œ íŒ¨í„´ ì •ì˜ (2025-06-26T15_09_46+09_00 í˜•ì‹)
        self.date_pattern = re.compile(r'\d{4}-\d{2}-\d{2}T\d{2}_\d{2}_\d{2}[+-]\d{2}_\d{2}')
        
        # === ë„êµ¬ ê°„ ê°„ë‹¨í•œ ë„¤ë¹„ê²Œì´ì…˜ ì»¨í…ìŠ¤íŠ¸ ===
        self.navigation_context = {
            'selected_user': None,        # í˜„ì¬ ì„ íƒëœ ì‚¬ìš©ì
            'source_tool': None,          # ì¶œë°œì  ë„êµ¬
            'return_callback': None,      # ëŒì•„ê°ˆ ë•Œ í˜¸ì¶œí•  ì½œë°±
        }
        
        logger.info("CapacityFinder ì´ˆê¸°í™” ì™„ë£Œ")
        
    def format_file_size(self, size_mb):
        """íŒŒì¼ ì‚¬ì´ì¦ˆë¥¼ ì ì ˆí•œ ë‹¨ìœ„(MB/GB)ë¡œ í¬ë§·íŒ…í•˜ëŠ” í•¨ìˆ˜"""
        if size_mb >= 1024:  # 1GB ì´ìƒ
            size_gb = size_mb / 1024
            return f"{size_gb:.2f} GB"
        else:
            return f"{size_mb:.2f} MB"
        
    def handle_path_confirmation(self, path):
        """GUIì—ì„œ ê²½ë¡œê°€ í™•ì¸ë˜ì—ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜"""
        import time
        start_time = time.time()
        logger.info(f"ê²½ë¡œ í™•ì¸ë¨: {path}")
        logger.info(f"ğŸ“Š ê²½ë¡œ ë¡œë”© ì‹œì‘: {path}")
        
        self.current_path = path
        
        # ê²½ë¡œë¥¼ ê¸°ë¡ì— ì¶”ê°€ (JSONì— ìë™ ì €ì¥)
        if self.path_history.add_path(path):
            logger.info(f"ê²½ë¡œê°€ ê¸°ë¡ì— ì €ì¥ë¨: {path}")
        
        # ê¸°ì¡´ ë°ì´í„° ì´ˆê¸°í™”
        self.dic_files = {}
        
        # íŒŒì¼ ìš©ëŸ‰ ê³„ì‚°
        logger.debug("íŒŒì¼ ëª©ë¡ ë° ìš©ëŸ‰ ê³„ì‚° ì‹œì‘")
        result_dict = self.listing_files()
        files_processed_time = time.time()
        logger.info(f"â±ï¸ íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ: {files_processed_time - start_time:.2f}ì´ˆ")
        
        if result_dict:
            # GUI ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
            self.window.clear_results()
            
            # ìš©ëŸ‰ ê¸°ì¤€ìœ¼ë¡œ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ (í° ê²ƒë¶€í„°)
            sorted_users = sorted(result_dict.items(), key=lambda x: x[1]['total_size'], reverse=True)
            
            # ì „ì²´ íŒŒì¼ í†µê³„ ê³„ì‚°
            total_files_size = sum(user_data['total_size'] for _, user_data in sorted_users)
            total_files_count = sum(len(user_data['files']) for _, user_data in sorted_users)
            formatted_total_size = self.format_file_size(total_files_size)
            
            logger.info(f"íŒŒì¼ ë¶„ì„ ì™„ë£Œ - ì´ {len(sorted_users)}ëª… ì‚¬ìš©ì, ì´ ìš©ëŸ‰: {formatted_total_size}, ì´ íŒŒì¼: {total_files_count}ê°œ")
            
            # ê²°ê³¼ë¥¼ GUIì— í‘œì‹œ (í—¤ë”ë¥¼ ê° ì—´ì— ë§ì¶° í‘œì‹œ)
            self.window.add_header_with_totals("ì‚¬ìš©ìë³„ íŒŒì¼ ìš©ëŸ‰ (ìš©ëŸ‰ í° ìˆœ)", formatted_total_size, total_files_count)
            for username, user_data in sorted_users:
                total_size = user_data['total_size']
                file_count = len(user_data['files'])
                formatted_size = self.format_file_size(total_size)
                
                # ìƒˆë¡œìš´ íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ì‚¬ìš©ì ë°ì´í„° ì¶”ê°€
                self.window.add_user_data(username, user_data, formatted_size)
                
                logger.debug(f"ì‚¬ìš©ì: {username}, ì´ ìš©ëŸ‰: {formatted_size}, íŒŒì¼ ìˆ˜: {file_count}")
            
            # CapacityFinder ì¸ìŠ¤í„´ìŠ¤ë¥¼ GUIì— ì„¤ì •í•˜ê³  ëª¨ë¸ ì •ë¦¬ ë²„íŠ¼ í™œì„±í™”
            self.window.set_capacity_finder(self)
            self.window.update_cleanup_button_state()
            
            # ì „ì²´ ë¡œë”© ì™„ë£Œ ì‹œê°„ ì¸¡ì •
            total_time = time.time() - start_time
            logger.info(f"ğŸ¯ ì „ì²´ ê²½ë¡œ ë¡œë”© ì™„ë£Œ: {total_time:.2f}ì´ˆ")
            logger.info(f"   ğŸ“Š íŒŒì¼ ì²˜ë¦¬: {files_processed_time - start_time:.2f}ì´ˆ")
            logger.info(f"   ğŸ–¥ï¸ GUI í‘œì‹œ: {total_time - (files_processed_time - start_time):.2f}ì´ˆ")
        else:
            logger.warning("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.window.add_result_to_list("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            self.window.update_cleanup_button_state()
            
            # ë¹ˆ ê²°ê³¼ ì²˜ë¦¬ ì‹œê°„ë„ ì¸¡ì •
            total_time = time.time() - start_time
            logger.info(f"ğŸ¯ ê²½ë¡œ ë¡œë”© ì™„ë£Œ (ë¹ˆ ê²°ê³¼): {total_time:.2f}ì´ˆ")
        
    def listing_files_capacity(self) -> list:
        """íŒŒì¼ ìš©ëŸ‰ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
        list_files = []
        if self.current_path:
            try:
                for file in os.listdir(self.current_path):
                    file_path = os.path.join(self.current_path, file)
                    # íŒŒì¼ì¸ì§€ í™•ì¸ (ë””ë ‰í† ë¦¬ ì œì™¸)
                    if os.path.isfile(file_path):
                        # ë¦¬ìŠ¤íŠ¸ì— íŒŒì¼ëª…, íŒŒì¼í¬ê¸° ì €ì¥ MB ë‹¨ìœ„
                        file_size_mb = os.path.getsize(file_path) / (1024 * 1024)
                        list_files.append([file, file_size_mb])
                logger.info(f"íŒŒì¼ ëª©ë¡ ì½ê¸° ì™„ë£Œ: {len(list_files)}ê°œ íŒŒì¼")
                return list_files
            except Exception as e:
                logger.error(f"íŒŒì¼ ëª©ë¡ ì½ê¸° ì˜¤ë¥˜: {e}")
                return []
        else:
            logger.warning("ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
    
    def listing_files(self):
        """íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ ì‚¬ìš©ìë³„ë¡œ ìš©ëŸ‰ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜"""
        import time
        start_time = time.time()
        
        file_list = self.listing_files_capacity()
        
        if not file_list:
            return {}
        
        parsing_start = time.time()
        logger.debug(f"íŒŒì¼ëª… íŒŒì‹± ì‹œì‘: {len(file_list)}ê°œ íŒŒì¼")
        
        parsed_count = 0
        for file_info in file_list:
            file_name = file_info[0]
            file_size = file_info[1]
            
            username = self.file_name_handle(file_name)
            if username:
                # ì‚¬ìš©ìë³„ ìš©ëŸ‰ ëˆ„ì 
                if username not in self.dic_files:
                    self.dic_files[username] = {'total_size': 0.0, 'files': []}
                self.dic_files[username]['total_size'] += file_size
                self.dic_files[username]['files'].append({'name': file_name, 'size': file_size})
                parsed_count += 1
            else:
                logger.warning(f"íŒŒì¼ëª… ì²˜ë¦¬ ë¶ˆê°€: {file_name}")
        
        parsing_time = time.time() - parsing_start
        total_time = time.time() - start_time
        
        logger.info(f"âš¡ íŒŒì¼ ë¶„ì„ ì™„ë£Œ:")
        logger.info(f"   ğŸ“ ì´ íŒŒì¼: {len(file_list)}ê°œ")
        logger.info(f"   ğŸ‘¥ ì¸ì‹ëœ ì‚¬ìš©ì: {len(self.dic_files)}ëª…")
        logger.info(f"   âœ… ì„±ê³µì ìœ¼ë¡œ íŒŒì‹±: {parsed_count}ê°œ")
        logger.info(f"   â±ï¸ íŒŒì‹± ì‹œê°„: {parsing_time:.3f}ì´ˆ")
        logger.info(f"   â±ï¸ ì „ì²´ ì‹œê°„: {total_time:.3f}ì´ˆ")
        
        return self.dic_files

    def file_name_handle(self, file_name):
        """íŒŒì¼ ì´ë¦„ì„ ì²˜ë¦¬í•´ì„œ ì±„ë„ëª…ë§Œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        ë‹¤ì–‘í•œ íŒŒì¼ëª… êµ¬ì¡° ì§€ì›:
        - ì‚¬ì´íŠ¸-ì±„ë„-ë‚ ì§œ
        - ì±„ë„-ì‚¬ì´íŠ¸-ë‚ ì§œ
        - ê¸°íƒ€ ì¡°í•©
        ì˜ˆ: instagram-john_doe-2025-06-26T15_09_46+09_00.txt -> john_doe ë°˜í™˜
        """
        if not file_name:
            return None
            
        try:
            # í™•ì¥ì ì œê±°
            name_without_ext = file_name.split('.')[0] if '.' in file_name else file_name
            
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            date_match = self.date_pattern.search(name_without_ext)
            if not date_match:
                logger.warning(f"ë‚ ì§œ íŒ¨í„´ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            date_part = date_match.group()
            date_start = date_match.start()
            
            # ë‚ ì§œ ì´ì „ ë¶€ë¶„ ì¶”ì¶œ
            before_date = name_without_ext[:date_start].rstrip('-')
            
            # '-'ë¡œ ë¶„ë¦¬
            parts = before_date.split('-')
            
            if len(parts) < 2:
                logger.warning(f"íŒŒì¼ëª… êµ¬ì¡°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ: {file_name}")
                return None
            
            # ì‚¬ì´íŠ¸ ì°¾ê¸°
            site_part = None
            channel_parts = []
            
            for i, part in enumerate(parts):
                if SiteType.is_valid_site(part):
                    site_part = part
                    # ì‚¬ì´íŠ¸ê°€ ì•„ë‹Œ ë‚˜ë¨¸ì§€ ë¶€ë¶„ë“¤ì„ ì±„ë„ëª…ìœ¼ë¡œ ê²°í•©
                    channel_parts = parts[:i] + parts[i+1:]
                    break
            
            if not site_part:
                logger.warning(f"ì•Œë ¤ì§„ ì‚¬ì´íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            if not channel_parts:
                logger.warning(f"ì±„ë„ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {file_name}")
                return None
            
            # ì±„ë„ëª… ê²°í•© (ì—¬ëŸ¬ ë¶€ë¶„ì´ ìˆì„ ê²½ìš° '-'ë¡œ ë‹¤ì‹œ ê²°í•©)
            channel_name = '-'.join(channel_parts)
            
            logger.debug(f"íŒŒì¼ëª… ì²˜ë¦¬ ì™„ë£Œ: {file_name} -> ì‚¬ì´íŠ¸: {site_part}, ì±„ë„: {channel_name}, ë‚ ì§œ: {date_part}")
            return channel_name
                    
        except Exception as e:
            logger.error(f"íŒŒì¼ëª… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return None

    def extract_date_from_filename(self, file_name):
        """íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ"""
        try:
            date_match = self.date_pattern.search(file_name)
            if date_match:
                date_str = date_match.group()
                # 2025-06-26T15_09_46+09_00 -> datetime ë³€í™˜
                file_date = datetime.fromisoformat(date_str.replace('_', ':'))
                return file_date
        except Exception as e:
            logger.error(f"ë‚ ì§œ ì¶”ì¶œ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
        return None

    def select_representative_samples(self, files):
        """ë” ëŒ€í‘œì„± ìˆëŠ” ìƒ˜í”Œ ì„ íƒ"""
        if len(files) <= 5:
            return files  # íŒŒì¼ ì ìœ¼ë©´ ë‹¤ ë³´ì—¬ì£¼ê¸°
        
        samples = []
        
        # íŒŒì¼ë“¤ì„ ë‚ ì§œìˆœìœ¼ë¡œ ì •ë ¬
        files_with_dates = []
        for file_info in files:
            file_date = self.extract_date_from_filename(file_info['name'])
            if file_date:
                files_with_dates.append({'file': file_info, 'date': file_date})
        
        if not files_with_dates:
            return files[:5]  # ë‚ ì§œ ì¶”ì¶œ ì‹¤íŒ¨ì‹œ ì²« 5ê°œ
        
        files_with_dates.sort(key=lambda x: x['date'])
        sorted_files = [item['file'] for item in files_with_dates]
        
        # 1. ê°€ì¥ ìµœê·¼ íŒŒì¼
        samples.append(sorted_files[-1])
        
        # 2. ê°€ì¥ í° íŒŒì¼  
        largest_file = max(files, key=lambda x: x['size'])
        if largest_file not in samples:
            samples.append(largest_file)
        
        # 3. ì‹œê°„ëŒ€ë³„ ë¶„ì‚° ìƒ˜í”Œ (ì²˜ìŒ/ì¤‘ê°„)
        if len(sorted_files) > 2:
            # ì²« ê¸°ë¡
            if sorted_files[0] not in samples:
                samples.append(sorted_files[0])
            # ì¤‘ê°„
            middle_file = sorted_files[len(sorted_files)//2]
            if middle_file not in samples:
                samples.append(middle_file)
        
        # 4. ë‚¨ì€ ìë¦¬ì— ë‹¤ë¥¸ íŒŒì¼ë“¤
        for file_info in files:
            if file_info not in samples and len(samples) < 5:
                samples.append(file_info)
        
        return samples[:5]  # ìµœëŒ€ 5ê°œ

    def create_decision_list(self):
        """ê²°ì •í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì •ë¦¬"""
        if not self.dic_files:
            logger.warning("ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ìš©ëŸ‰ í° ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_models = sorted(
            self.dic_files.items(), 
            key=lambda x: x[1]['total_size'], 
            reverse=True
        )
        
        decision_list = []
        for username, data in sorted_models:
            # ëŒ€í‘œ íŒŒì¼ë“¤ ì„ íƒ
            sample_files = self.select_representative_samples(data['files'])
            
            decision_list.append({
                'username': username,
                'total_size': data['total_size'],
                'file_count': len(data['files']),
                'sample_files': sample_files,
                'potential_savings': data['total_size']  # ì‚­ì œì‹œ ì ˆì•½ ìš©ëŸ‰
            })
        
        return decision_list

    def compare_user_sites(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ ì‚¬ì´íŠ¸ë³„ íŒŒì¼ ë¹„êµ ë° ì¤‘ë³µ ì œê±° ì¶”ì²œ
        
        Args:
            username: ë¹„êµí•  ì‚¬ìš©ìëª…
            
        Returns:
            dict: {
                'files_to_delete': [{'name': str, 'size': float, 'site': str, 'date': str}],
                'total_savings': float,
                'username': str,
                'comparison_results': [dict]  # ë¹„êµ ê²°ê³¼ ìƒì„¸
            }
        """
        if username not in self.dic_files:
            return None
        
        user_files = self.dic_files[username]['files']
        
        # íŒŒì¼ë“¤ì„ ì‚¬ì´íŠ¸ë³„, ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”
        date_site_groups = {}  # {date: {site: [files]}}
        
        for file_info in user_files:
            file_name = file_info['name']
            file_size = file_info['size']
            
            # íŒŒì¼ëª…ì—ì„œ ì‚¬ì´íŠ¸ì™€ ë‚ ì§œ ì¶”ì¶œ
            site, date_str = self.extract_site_and_date(file_name)
            if not site or not date_str:
                continue
            
            if date_str not in date_site_groups:
                date_site_groups[date_str] = {}
            
            if site not in date_site_groups[date_str]:
                date_site_groups[date_str][site] = []
            
            date_site_groups[date_str][site].append({
                'name': file_name,
                'size': file_size,
                'site': site,
                'date': date_str
            })
        
        # ê°™ì€ ë‚ ì§œì— ì—¬ëŸ¬ ì‚¬ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš° ìš©ëŸ‰ ë¹„êµ
        files_to_delete = []
        comparison_results = []
        total_savings = 0
        
        for date_str, sites in date_site_groups.items():
            if len(sites) <= 1:
                continue  # ì‚¬ì´íŠ¸ê°€ í•˜ë‚˜ë¿ì´ë©´ ë¹„êµí•  í•„ìš” ì—†ìŒ
            
            # ì‚¬ì´íŠ¸ë³„ ì´ ìš©ëŸ‰ ê³„ì‚°
            site_totals = {}
            for site, files in sites.items():
                site_totals[site] = sum(f['size'] for f in files)
            
            # ê°€ì¥ í° ìš©ëŸ‰ì˜ ì‚¬ì´íŠ¸ ì°¾ê¸°
            max_site = max(site_totals.items(), key=lambda x: x[1])
            max_site_name = max_site[0]
            max_size = max_site[1]
            
            # ë‹¤ë¥¸ ì‚¬ì´íŠ¸ë“¤ì˜ íŒŒì¼ì„ ì‚­ì œ ëŒ€ìƒìœ¼ë¡œ ì¶”ê°€
            comparison_result = {
                'date': date_str,
                'sites': {},
                'keep_site': max_site_name,
                'delete_sites': []
            }
            
            for site, files in sites.items():
                site_total = site_totals[site]
                comparison_result['sites'][site] = {
                    'files': files,
                    'total_size': site_total,
                    'file_count': len(files)
                }
                
                if site != max_site_name:
                    # ì‘ì€ ìš©ëŸ‰ì˜ ì‚¬ì´íŠ¸ íŒŒì¼ë“¤ì„ ì‚­ì œ ëŒ€ìƒì— ì¶”ê°€
                    for file_info in files:
                        files_to_delete.append(file_info)
                        total_savings += file_info['size']
                    comparison_result['delete_sites'].append(site)
            
            comparison_results.append(comparison_result)
        
        return {
            'files_to_delete': files_to_delete,
            'total_savings': total_savings,
            'username': username,
            'comparison_results': comparison_results
        }
    
    def extract_site_and_date(self, file_name):
        """íŒŒì¼ëª…ì—ì„œ ì‚¬ì´íŠ¸ì™€ ë‚ ì§œë¥¼ ì¶”ì¶œ
        
        Args:
            file_name: íŒŒì¼ëª…
            
        Returns:
            tuple: (site, date_str) ë˜ëŠ” (None, None)
        """
        if not file_name:
            return None, None
            
        try:
            # í™•ì¥ì ì œê±°
            name_without_ext = file_name.split('.')[0] if '.' in file_name else file_name
            
            # ë‚ ì§œ íŒ¨í„´ ì°¾ê¸°
            date_match = self.date_pattern.search(name_without_ext)
            if not date_match:
                return None, None
            
            date_part = date_match.group()
            date_start = date_match.start()
            
            # ë‚ ì§œ ì´ì „ ë¶€ë¶„ ì¶”ì¶œ
            before_date = name_without_ext[:date_start].rstrip('-')
            
            # '-'ë¡œ ë¶„ë¦¬
            parts = before_date.split('-')
            
            if len(parts) < 2:
                return None, None
            
            # ì‚¬ì´íŠ¸ ì°¾ê¸°
            for part in parts:
                if SiteType.is_valid_site(part):
                    # ë‚ ì§œì—ì„œ ì‹œê°„ ë¶€ë¶„ë§Œ ì¶”ì¶œí•´ì„œ ë‚ ì§œë¡œ ë³€í™˜ (2025-06-26 í˜•ì‹)
                    date_only = date_part.split('T')[0] if 'T' in date_part else date_part
                    return part, date_only
            
            return None, None
                    
        except Exception as e:
            logger.error(f"ì‚¬ì´íŠ¸/ë‚ ì§œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return None, None

    def get_available_users(self):
        """ë¶„ì„ëœ ì‚¬ìš©ì ëª©ë¡ ë°˜í™˜"""
        if not self.dic_files:
            return []
        return list(self.dic_files.keys())

    def calculate_file_score(self, file_info, user_files):
        """íŒŒì¼ì˜ ë©”íƒ€ë°ì´í„° ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        
        Args:
            file_info: ê°œë³„ íŒŒì¼ ì •ë³´
            user_files: í•´ë‹¹ ì‚¬ìš©ìì˜ ì „ì²´ íŒŒì¼ ëª©ë¡
            
        Returns:
            float: 0.0 ~ 1.0 ì‚¬ì´ì˜ ì ìˆ˜
        """
        file_name = file_info['name']
        file_size = file_info['size']
        
        # ê¸°ë³¸ ì ìˆ˜ êµ¬ì„± ìš”ì†Œë“¤
        size_score = 0.0
        rarity_score = 0.0
        date_score = 0.0
        
        try:
            # 1. íŒŒì¼ í¬ê¸° ì ìˆ˜ (60% ê°€ì¤‘ì¹˜) - ì¦ê°€
            all_sizes = [f['size'] for f in user_files]
            if all_sizes:
                max_size = max(all_sizes)
                min_size = min(all_sizes)
                if max_size > min_size:
                    # í¬ê¸° ì ìˆ˜ë¥¼ ë” ê´€ëŒ€í•˜ê²Œ ê³„ì‚° (ìƒìœ„ 30% ì´ìƒì´ë©´ 0.8+ ì ìˆ˜)
                    normalized_score = (file_size - min_size) / (max_size - min_size)
                    # ì œê³±ê·¼ ì ìš©í•´ì„œ ì¤‘ê°„ê°’ë“¤ë„ ë” ë†’ì€ ì ìˆ˜ ë°›ë„ë¡
                    size_score = min(normalized_score ** 0.5, 1.0)
                else:
                    size_score = 1.0
            
            # 2. í¬ê·€ì„± ì ìˆ˜ (25% ê°€ì¤‘ì¹˜) - ì¦ê°€
            file_date = self.extract_date_from_filename(file_name)
            if file_date:
                # ê°™ì€ ë‚ ì§œì˜ íŒŒì¼ ìˆ˜ê°€ ì ì„ìˆ˜ë¡ í¬ê·€í•¨
                same_date_count = 0
                for f in user_files:
                    f_date = self.extract_date_from_filename(f['name'])
                    if f_date and f_date.date() == file_date.date():
                        same_date_count += 1
                
                if same_date_count <= 1:
                    rarity_score = 1.0
                elif same_date_count <= 2:
                    rarity_score = 0.9
                elif same_date_count <= 3:
                    rarity_score = 0.8
                elif same_date_count <= 5:
                    rarity_score = 0.7
                else:
                    rarity_score = 0.5
            else:
                # ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼ì€ ì¤‘ê°„ ì ìˆ˜
                rarity_score = 0.6
            
            # 3. ë‚ ì§œ ì ìˆ˜ (15% ê°€ì¤‘ì¹˜) - ì¦ê°€, ìµœê·¼ì¼ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
            if file_date:
                all_dates = []
                for f in user_files:
                    f_date = self.extract_date_from_filename(f['name'])
                    if f_date:
                        all_dates.append(f_date)
                
                if all_dates:
                    all_dates.sort()
                    oldest = all_dates[0]
                    newest = all_dates[-1]
                    
                    if newest > oldest:
                        total_days = (newest - oldest).days
                        file_days = (file_date - oldest).days
                        date_score = file_days / total_days if total_days > 0 else 1.0
                    else:
                        date_score = 1.0
                else:
                    date_score = 0.8
            else:
                # ë‚ ì§œë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ëŠ” íŒŒì¼ì€ ì¤‘ê°„ ì ìˆ˜
                date_score = 0.5
        
        except Exception as e:
            logger.error(f"ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {file_name}, ì—ëŸ¬: {e}")
            return 0.6  # ê¸°ë³¸ê°’ì„ 0.6ìœ¼ë¡œ ìƒí–¥
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚° (ì‹œê°„ ì ìˆ˜ ì œê±°, ë‹¤ë¥¸ ìš”ì†Œë“¤ ê°€ì¤‘ì¹˜ ì¦ê°€)
        final_score = (size_score * 0.6 + rarity_score * 0.25 + date_score * 0.15)
        
        # ì¶”ê°€ ë³´ë„ˆìŠ¤: ë§¤ìš° í° íŒŒì¼ì—ê²Œ ë³´ë„ˆìŠ¤ ì ìˆ˜
        if all_sizes:
            size_percentile = (file_size - min(all_sizes)) / (max(all_sizes) - min(all_sizes)) if max(all_sizes) > min(all_sizes) else 1.0
            if size_percentile >= 0.9:  # ìƒìœ„ 10% í¬ê¸°
                final_score = min(final_score + 0.1, 1.0)
            elif size_percentile >= 0.8:  # ìƒìœ„ 20% í¬ê¸°
                final_score = min(final_score + 0.05, 1.0)
        
        return min(max(final_score, 0.0), 1.0)  # 0.0 ~ 1.0 ì‚¬ì´ë¡œ í´ë¨í•‘

    def get_user_files_with_scores(self, username):
        """íŠ¹ì • ì‚¬ìš©ìì˜ íŒŒì¼ë“¤ì„ ì ìˆ˜ì™€ í•¨ê»˜ ë°˜í™˜
        
        Args:
            username: ì‚¬ìš©ìëª…
            
        Returns:
            list: [{'name': str, 'size': float, 'score': float, 'rank': int}, ...]
        """
        if username not in self.dic_files:
            return []
        
        user_files = self.dic_files[username]['files']
        
        # ê° íŒŒì¼ì— ì ìˆ˜ ì¶”ê°€
        files_with_scores = []
        for file_info in user_files:
            score = self.calculate_file_score(file_info, user_files)
            files_with_scores.append({
                'name': file_info['name'],
                'size': file_info['size'],
                'score': score,
                'rank': 0  # ë‚˜ì¤‘ì— ì„¤ì •
            })
        
        # ì ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ë†’ì€ ì ìˆ˜ë¶€í„°)
        files_with_scores.sort(key=lambda x: x['score'], reverse=True)
        
        # ìˆœìœ„ ì„¤ì •
        for i, file_info in enumerate(files_with_scores):
            file_info['rank'] = i + 1
        
        return files_with_scores

    def get_selection_candidates(self, username, top_n=50):
        """ì„ ë³„ í›„ë³´ íŒŒì¼ë“¤ ë°˜í™˜ (ìƒìœ„ Nê°œ)
        
        Args:
            username: ì‚¬ìš©ìëª…
            top_n: í›„ë³´ë¡œ ì„ íƒí•  íŒŒì¼ ìˆ˜
            
        Returns:
            dict: {
                'candidates': list,  # ì„ ë³„ í›„ë³´ íŒŒì¼ë“¤
                'excluded': list,    # ìë™ ì œì™¸ëœ íŒŒì¼ë“¤
                'total_files': int,  # ì „ì²´ íŒŒì¼ ìˆ˜
                'username': str
            }
        """
        if username not in self.dic_files:
            return None
        
        all_files = self.get_user_files_with_scores(username)
        total_files = len(all_files)
        
        # ìƒìœ„ Nê°œë¥¼ í›„ë³´ë¡œ ì„ íƒ
        top_n = min(top_n, total_files)
        candidates = all_files[:top_n]
        excluded = all_files[top_n:]
        
        return {
            'candidates': candidates,
            'excluded': excluded,
            'total_files': total_files,
            'username': username
        }

def main():
    """ë©”ì¸ í•¨ìˆ˜ì—ì„œ GUI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    app = QApplication(sys.argv)
    
    # CapacityFinder ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    finder = CapacityFinder()
    
    # GUI ìƒì„± ì‹œ ì½œë°± í•¨ìˆ˜ì™€ ê²½ë¡œ ê¸°ë¡ ì „ë‹¬
    finder.window = MainWindow(
        on_path_confirmed=finder.handle_path_confirmation,
        path_history=finder.path_history
    )
    finder.window.show()
    
    sys.exit(app.exec_())

if __name__ == '__main__':
    main()
